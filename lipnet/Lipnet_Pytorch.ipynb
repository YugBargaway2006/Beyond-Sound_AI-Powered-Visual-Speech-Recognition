{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Beyond-Sound_AI-Powered-Visual-Speech-Recognition"
      ],
      "metadata": {
        "id": "X63QobTULmc9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBtsvynkwP6C"
      },
      "source": [
        "## 1.1. Install and Import Dependencies\n",
        "\n",
        "We will be requiring a bunch of different python libraries for video processing and model creation purposes. Its better to check beforehand if all the libraries are properly installed and imported to avoid unnecessary errors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "84_BPVyRMgEv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9LOXgA4gwTtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2132e84-526f-4a69-f00b-08bb4797d74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.8.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imageio) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio) (11.3.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  Check if the libraries are installed properly\n",
        "\n",
        "'''\n",
        "\n",
        "!pip install torch   # Allow us to build our neural network. Chosen PyTorch for this task.\n",
        "!pip install torchvision   # Torchvision library provides extra features and functions to process visual information\n",
        "!pip install opencv-python   # Library for Image and Video transformations\n",
        "!pip install matplotlib   # Helps visualize how our preprocessed videos and frames looks like\n",
        "!pip install imageio   # Creates gif from image frames, thus letting us know what's happening in multiple frames stacked together\n",
        "!pip install gdown   # Allow us to download dataset from google drive. Can also use kagglehub for datasets in kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F-80X51uwTqX"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Import the required dependencies.\n",
        "\n",
        "'''\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "from torchvision import transforms\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Check if the libraries are properly imported.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "print(\"OpenCV version: \", cv2.__version__)\n",
        "print(\"NumPy version: \", np.__version__)\n",
        "print(\"ImageIO version: \", imageio.__version__)"
      ],
      "metadata": {
        "id": "BXqDPnitOI9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b307e106-69aa-417e-de09-4601cfea99c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV version:  4.12.0\n",
            "NumPy version:  2.0.2\n",
            "ImageIO version:  2.37.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyYLXuRGwTn4",
        "outputId": "f5ed1b67-8ca5-4f14-f995-6fb3667d11f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: False\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  Check if GPU is available in the system. We will shift the model to GPU for faster training.\n",
        "\n",
        "'''\n",
        "\n",
        "gpu_aval = torch.cuda.is_available()\n",
        "print(f\"GPU available: {gpu_aval}\")\n",
        "\n",
        "if gpu_aval:\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKs5wLcrOmbI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uDu-6C2xFu2"
      },
      "source": [
        "# 1. Build Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lAd9E4rqwTgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f4a7c9-1ef9-4088-8d00-ef9cbfa380ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL\n",
            "From (redirected): https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL&confirm=t&uuid=df57adb8-c8b7-45af-acc5-ed6f0bc9f6bb\n",
            "To: /content/data.zip\n",
            "100%|██████████| 423M/423M [00:04<00:00, 88.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/',\n",
              " 'data/alignments/',\n",
              " 'data/alignments/s1/',\n",
              " 'data/alignments/s1/bbaf2n.align',\n",
              " 'data/alignments/s1/bbaf3s.align',\n",
              " 'data/alignments/s1/bbaf4p.align',\n",
              " 'data/alignments/s1/bbaf5a.align',\n",
              " 'data/alignments/s1/bbal6n.align',\n",
              " 'data/alignments/s1/bbal7s.align',\n",
              " 'data/alignments/s1/bbal8p.align',\n",
              " 'data/alignments/s1/bbal9a.align',\n",
              " 'data/alignments/s1/bbas1s.align',\n",
              " 'data/alignments/s1/bbas2p.align',\n",
              " 'data/alignments/s1/bbas3a.align',\n",
              " 'data/alignments/s1/bbaszn.align',\n",
              " 'data/alignments/s1/bbaz4n.align',\n",
              " 'data/alignments/s1/bbaz5s.align',\n",
              " 'data/alignments/s1/bbaz6p.align',\n",
              " 'data/alignments/s1/bbaz7a.align',\n",
              " 'data/alignments/s1/bbbf6n.align',\n",
              " 'data/alignments/s1/bbbf7s.align',\n",
              " 'data/alignments/s1/bbbf8p.align',\n",
              " 'data/alignments/s1/bbbf9a.align',\n",
              " 'data/alignments/s1/bbbm1s.align',\n",
              " 'data/alignments/s1/bbbm2p.align',\n",
              " 'data/alignments/s1/bbbm3a.align',\n",
              " 'data/alignments/s1/bbbmzn.align',\n",
              " 'data/alignments/s1/bbbs4n.align',\n",
              " 'data/alignments/s1/bbbs5s.align',\n",
              " 'data/alignments/s1/bbbs6p.align',\n",
              " 'data/alignments/s1/bbbs7a.align',\n",
              " 'data/alignments/s1/bbbz8n.align',\n",
              " 'data/alignments/s1/bbbz9s.align',\n",
              " 'data/alignments/s1/bbie8n.align',\n",
              " 'data/alignments/s1/bbie9s.align',\n",
              " 'data/alignments/s1/bbif1a.align',\n",
              " 'data/alignments/s1/bbifzp.align',\n",
              " 'data/alignments/s1/bbil2n.align',\n",
              " 'data/alignments/s1/bbil3s.align',\n",
              " 'data/alignments/s1/bbil4p.align',\n",
              " 'data/alignments/s1/bbil5a.align',\n",
              " 'data/alignments/s1/bbir6n.align',\n",
              " 'data/alignments/s1/bbir7s.align',\n",
              " 'data/alignments/s1/bbir8p.align',\n",
              " 'data/alignments/s1/bbir9a.align',\n",
              " 'data/alignments/s1/bbiz1s.align',\n",
              " 'data/alignments/s1/bbiz2p.align',\n",
              " 'data/alignments/s1/bbiz3a.align',\n",
              " 'data/alignments/s1/bbizzn.align',\n",
              " 'data/alignments/s1/bbwg1s.align',\n",
              " 'data/alignments/s1/bbwg2p.align',\n",
              " 'data/alignments/s1/bbwg3a.align',\n",
              " 'data/alignments/s1/bbwgzn.align',\n",
              " 'data/alignments/s1/bbwm4n.align',\n",
              " 'data/alignments/s1/bbwm5s.align',\n",
              " 'data/alignments/s1/bbwm6p.align',\n",
              " 'data/alignments/s1/bbwm7a.align',\n",
              " 'data/alignments/s1/bbws8n.align',\n",
              " 'data/alignments/s1/bbws9s.align',\n",
              " 'data/alignments/s1/bbwt1a.align',\n",
              " 'data/alignments/s1/bbwtzp.align',\n",
              " 'data/alignments/s1/bgaa6n.align',\n",
              " 'data/alignments/s1/bgaa7s.align',\n",
              " 'data/alignments/s1/bgaa8p.align',\n",
              " 'data/alignments/s1/bgaa9a.align',\n",
              " 'data/alignments/s1/bgah1s.align',\n",
              " 'data/alignments/s1/bgah2p.align',\n",
              " 'data/alignments/s1/bgah3a.align',\n",
              " 'data/alignments/s1/bgahzn.align',\n",
              " 'data/alignments/s1/bgan4n.align',\n",
              " 'data/alignments/s1/bgan5s.align',\n",
              " 'data/alignments/s1/bgan6p.align',\n",
              " 'data/alignments/s1/bgan7a.align',\n",
              " 'data/alignments/s1/bgat8n.align',\n",
              " 'data/alignments/s1/bgat9s.align',\n",
              " 'data/alignments/s1/bgau1a.align',\n",
              " 'data/alignments/s1/bgauzp.align',\n",
              " 'data/alignments/s1/bgbb1s.align',\n",
              " 'data/alignments/s1/bgbb2p.align',\n",
              " 'data/alignments/s1/bgbb3a.align',\n",
              " 'data/alignments/s1/bgbbzn.align',\n",
              " 'data/alignments/s1/bgbh4n.align',\n",
              " 'data/alignments/s1/bgbh5s.align',\n",
              " 'data/alignments/s1/bgbh6p.align',\n",
              " 'data/alignments/s1/bgbh7a.align',\n",
              " 'data/alignments/s1/bgbn8n.align',\n",
              " 'data/alignments/s1/bgbn9s.align',\n",
              " 'data/alignments/s1/bgbo1a.align',\n",
              " 'data/alignments/s1/bgbozp.align',\n",
              " 'data/alignments/s1/bgbu2n.align',\n",
              " 'data/alignments/s1/bgbu3s.align',\n",
              " 'data/alignments/s1/bgbu4p.align',\n",
              " 'data/alignments/s1/bgbu5a.align',\n",
              " 'data/alignments/s1/bgia2n.align',\n",
              " 'data/alignments/s1/bgia3s.align',\n",
              " 'data/alignments/s1/bgia4p.align',\n",
              " 'data/alignments/s1/bgia5a.align',\n",
              " 'data/alignments/s1/bgig6n.align',\n",
              " 'data/alignments/s1/bgig7s.align',\n",
              " 'data/alignments/s1/bgig8p.align',\n",
              " 'data/alignments/s1/bgig9a.align',\n",
              " 'data/alignments/s1/bgin1s.align',\n",
              " 'data/alignments/s1/bgin2p.align',\n",
              " 'data/alignments/s1/bgin3a.align',\n",
              " 'data/alignments/s1/bginzn.align',\n",
              " 'data/alignments/s1/bgit4n.align',\n",
              " 'data/alignments/s1/bgit5s.align',\n",
              " 'data/alignments/s1/bgit6p.align',\n",
              " 'data/alignments/s1/bgit7a.align',\n",
              " 'data/alignments/s1/bgwb4n.align',\n",
              " 'data/alignments/s1/bgwb5s.align',\n",
              " 'data/alignments/s1/bgwb6p.align',\n",
              " 'data/alignments/s1/bgwb7a.align',\n",
              " 'data/alignments/s1/bgwh8n.align',\n",
              " 'data/alignments/s1/bgwh9s.align',\n",
              " 'data/alignments/s1/bgwi1a.align',\n",
              " 'data/alignments/s1/bgwizp.align',\n",
              " 'data/alignments/s1/bgwo2n.align',\n",
              " 'data/alignments/s1/bgwo3s.align',\n",
              " 'data/alignments/s1/bgwo4p.align',\n",
              " 'data/alignments/s1/bgwo5a.align',\n",
              " 'data/alignments/s1/bgwu6n.align',\n",
              " 'data/alignments/s1/bgwu7s.align',\n",
              " 'data/alignments/s1/bgwu8p.align',\n",
              " 'data/alignments/s1/bgwu9a.align',\n",
              " 'data/alignments/s1/braf8n.align',\n",
              " 'data/alignments/s1/braf9s.align',\n",
              " 'data/alignments/s1/brag1a.align',\n",
              " 'data/alignments/s1/bragzp.align',\n",
              " 'data/alignments/s1/bram2n.align',\n",
              " 'data/alignments/s1/bram3s.align',\n",
              " 'data/alignments/s1/bram4p.align',\n",
              " 'data/alignments/s1/bram5a.align',\n",
              " 'data/alignments/s1/bras6n.align',\n",
              " 'data/alignments/s1/bras7s.align',\n",
              " 'data/alignments/s1/bras8p.align',\n",
              " 'data/alignments/s1/bras9a.align',\n",
              " 'data/alignments/s1/brba1a.align',\n",
              " 'data/alignments/s1/brbazp.align',\n",
              " 'data/alignments/s1/brbg2n.align',\n",
              " 'data/alignments/s1/brbg3s.align',\n",
              " 'data/alignments/s1/brbg4p.align',\n",
              " 'data/alignments/s1/brbg5a.align',\n",
              " 'data/alignments/s1/brbm6n.align',\n",
              " 'data/alignments/s1/brbm7s.align',\n",
              " 'data/alignments/s1/brbm8p.align',\n",
              " 'data/alignments/s1/brbm9a.align',\n",
              " 'data/alignments/s1/brbt1s.align',\n",
              " 'data/alignments/s1/brbt2p.align',\n",
              " 'data/alignments/s1/brbt3a.align',\n",
              " 'data/alignments/s1/brbtzn.align',\n",
              " 'data/alignments/s1/brif4n.align',\n",
              " 'data/alignments/s1/brif5s.align',\n",
              " 'data/alignments/s1/brif6p.align',\n",
              " 'data/alignments/s1/brif7a.align',\n",
              " 'data/alignments/s1/bril8n.align',\n",
              " 'data/alignments/s1/bril9s.align',\n",
              " 'data/alignments/s1/brim1a.align',\n",
              " 'data/alignments/s1/brimzp.align',\n",
              " 'data/alignments/s1/bris2n.align',\n",
              " 'data/alignments/s1/bris3s.align',\n",
              " 'data/alignments/s1/bris4p.align',\n",
              " 'data/alignments/s1/bris5a.align',\n",
              " 'data/alignments/s1/briz6n.align',\n",
              " 'data/alignments/s1/briz7s.align',\n",
              " 'data/alignments/s1/briz8p.align',\n",
              " 'data/alignments/s1/briz9a.align',\n",
              " 'data/alignments/s1/brwa2n.align',\n",
              " 'data/alignments/s1/brwa3s.align',\n",
              " 'data/alignments/s1/brwa4p.align',\n",
              " 'data/alignments/s1/brwa5a.align',\n",
              " 'data/alignments/s1/brwg6n.align',\n",
              " 'data/alignments/s1/brwg7s.align',\n",
              " 'data/alignments/s1/brwg8p.align',\n",
              " 'data/alignments/s1/brwg9a.align',\n",
              " 'data/alignments/s1/brwn1s.align',\n",
              " 'data/alignments/s1/brwn2p.align',\n",
              " 'data/alignments/s1/brwn3a.align',\n",
              " 'data/alignments/s1/brwnzn.align',\n",
              " 'data/alignments/s1/brwt4n.align',\n",
              " 'data/alignments/s1/brwt5s.align',\n",
              " 'data/alignments/s1/brwt6p.align',\n",
              " 'data/alignments/s1/brwt7a.align',\n",
              " 'data/alignments/s1/bwaa1s.align',\n",
              " 'data/alignments/s1/bwaa2p.align',\n",
              " 'data/alignments/s1/bwaa3a.align',\n",
              " 'data/alignments/s1/bwaazn.align',\n",
              " 'data/alignments/s1/bwag4n.align',\n",
              " 'data/alignments/s1/bwag5s.align',\n",
              " 'data/alignments/s1/bwag6p.align',\n",
              " 'data/alignments/s1/bwag7a.align',\n",
              " 'data/alignments/s1/bwam8n.align',\n",
              " 'data/alignments/s1/bwam9s.align',\n",
              " 'data/alignments/s1/bwan1a.align',\n",
              " 'data/alignments/s1/bwanzp.align',\n",
              " 'data/alignments/s1/bwat2n.align',\n",
              " 'data/alignments/s1/bwat3s.align',\n",
              " 'data/alignments/s1/bwat4p.align',\n",
              " 'data/alignments/s1/bwat5a.align',\n",
              " 'data/alignments/s1/bwba4n.align',\n",
              " 'data/alignments/s1/bwba5s.align',\n",
              " 'data/alignments/s1/bwba6p.align',\n",
              " 'data/alignments/s1/bwba7a.align',\n",
              " 'data/alignments/s1/bwbg8n.align',\n",
              " 'data/alignments/s1/bwbg9s.align',\n",
              " 'data/alignments/s1/bwbh1a.align',\n",
              " 'data/alignments/s1/bwbhzp.align',\n",
              " 'data/alignments/s1/bwbn2n.align',\n",
              " 'data/alignments/s1/bwbn3s.align',\n",
              " 'data/alignments/s1/bwbn4p.align',\n",
              " 'data/alignments/s1/bwbn5a.align',\n",
              " 'data/alignments/s1/bwbt6n.align',\n",
              " 'data/alignments/s1/bwbt7s.align',\n",
              " 'data/alignments/s1/bwbt8p.align',\n",
              " 'data/alignments/s1/bwbt9a.align',\n",
              " 'data/alignments/s1/bwig1s.align',\n",
              " 'data/alignments/s1/bwig2p.align',\n",
              " 'data/alignments/s1/bwig3a.align',\n",
              " 'data/alignments/s1/bwigzn.align',\n",
              " 'data/alignments/s1/bwim4n.align',\n",
              " 'data/alignments/s1/bwim5s.align',\n",
              " 'data/alignments/s1/bwim6p.align',\n",
              " 'data/alignments/s1/bwim7a.align',\n",
              " 'data/alignments/s1/bwis8n.align',\n",
              " 'data/alignments/s1/bwis9s.align',\n",
              " 'data/alignments/s1/bwit1a.align',\n",
              " 'data/alignments/s1/bwitzp.align',\n",
              " 'data/alignments/s1/bwwa8n.align',\n",
              " 'data/alignments/s1/bwwa9s.align',\n",
              " 'data/alignments/s1/bwwb1a.align',\n",
              " 'data/alignments/s1/bwwbzp.align',\n",
              " 'data/alignments/s1/bwwh2n.align',\n",
              " 'data/alignments/s1/bwwh3s.align',\n",
              " 'data/alignments/s1/bwwh4p.align',\n",
              " 'data/alignments/s1/bwwh5a.align',\n",
              " 'data/alignments/s1/bwwn6n.align',\n",
              " 'data/alignments/s1/bwwn7s.align',\n",
              " 'data/alignments/s1/bwwn8p.align',\n",
              " 'data/alignments/s1/bwwn9a.align',\n",
              " 'data/alignments/s1/bwwu1s.align',\n",
              " 'data/alignments/s1/bwwu2p.align',\n",
              " 'data/alignments/s1/bwwu3a.align',\n",
              " 'data/alignments/s1/bwwuzn.align',\n",
              " 'data/alignments/s1/lbad6n.align',\n",
              " 'data/alignments/s1/lbad7s.align',\n",
              " 'data/alignments/s1/lbad8p.align',\n",
              " 'data/alignments/s1/lbad9a.align',\n",
              " 'data/alignments/s1/lbak1s.align',\n",
              " 'data/alignments/s1/lbak2p.align',\n",
              " 'data/alignments/s1/lbak3a.align',\n",
              " 'data/alignments/s1/lbakzn.align',\n",
              " 'data/alignments/s1/lbaq4n.align',\n",
              " 'data/alignments/s1/lbaq5s.align',\n",
              " 'data/alignments/s1/lbaq6p.align',\n",
              " 'data/alignments/s1/lbaq7a.align',\n",
              " 'data/alignments/s1/lbax8n.align',\n",
              " 'data/alignments/s1/lbax9s.align',\n",
              " 'data/alignments/s1/lbay1a.align',\n",
              " 'data/alignments/s1/lbayzp.align',\n",
              " 'data/alignments/s1/lbbe1s.align',\n",
              " 'data/alignments/s1/lbbe2p.align',\n",
              " 'data/alignments/s1/lbbe3a.align',\n",
              " 'data/alignments/s1/lbbezn.align',\n",
              " 'data/alignments/s1/lbbk4n.align',\n",
              " 'data/alignments/s1/lbbk5s.align',\n",
              " 'data/alignments/s1/lbbk6p.align',\n",
              " 'data/alignments/s1/lbbk7a.align',\n",
              " 'data/alignments/s1/lbbq8n.align',\n",
              " 'data/alignments/s1/lbbq9s.align',\n",
              " 'data/alignments/s1/lbbr1a.align',\n",
              " 'data/alignments/s1/lbbrzp.align',\n",
              " 'data/alignments/s1/lbby2n.align',\n",
              " 'data/alignments/s1/lbby3s.align',\n",
              " 'data/alignments/s1/lbby4p.align',\n",
              " 'data/alignments/s1/lbby5a.align',\n",
              " 'data/alignments/s1/lbid2n.align',\n",
              " 'data/alignments/s1/lbid3s.align',\n",
              " 'data/alignments/s1/lbid4p.align',\n",
              " 'data/alignments/s1/lbid5a.align',\n",
              " 'data/alignments/s1/lbij6n.align',\n",
              " 'data/alignments/s1/lbij7s.align',\n",
              " 'data/alignments/s1/lbij8p.align',\n",
              " 'data/alignments/s1/lbij9a.align',\n",
              " 'data/alignments/s1/lbiq1s.align',\n",
              " 'data/alignments/s1/lbiq2p.align',\n",
              " 'data/alignments/s1/lbiq3a.align',\n",
              " 'data/alignments/s1/lbiqzn.align',\n",
              " 'data/alignments/s1/lbix4n.align',\n",
              " 'data/alignments/s1/lbix5s.align',\n",
              " 'data/alignments/s1/lbix6p.align',\n",
              " 'data/alignments/s1/lbix7a.align',\n",
              " 'data/alignments/s1/lbwe4n.align',\n",
              " 'data/alignments/s1/lbwe5s.align',\n",
              " 'data/alignments/s1/lbwe6p.align',\n",
              " 'data/alignments/s1/lbwe7a.align',\n",
              " 'data/alignments/s1/lbwk8n.align',\n",
              " 'data/alignments/s1/lbwk9s.align',\n",
              " 'data/alignments/s1/lbwl1a.align',\n",
              " 'data/alignments/s1/lbwlzp.align',\n",
              " 'data/alignments/s1/lbwr2n.align',\n",
              " 'data/alignments/s1/lbwr3s.align',\n",
              " 'data/alignments/s1/lbwr4p.align',\n",
              " 'data/alignments/s1/lbwr5a.align',\n",
              " 'data/alignments/s1/lbwy6n.align',\n",
              " 'data/alignments/s1/lbwy7s.align',\n",
              " 'data/alignments/s1/lbwy8p.align',\n",
              " 'data/alignments/s1/lbwy9a.align',\n",
              " 'data/alignments/s1/lgaf4n.align',\n",
              " 'data/alignments/s1/lgaf5s.align',\n",
              " 'data/alignments/s1/lgaf6p.align',\n",
              " 'data/alignments/s1/lgaf7a.align',\n",
              " 'data/alignments/s1/lgal8n.align',\n",
              " 'data/alignments/s1/lgal9s.align',\n",
              " 'data/alignments/s1/lgam1a.align',\n",
              " 'data/alignments/s1/lgamzp.align',\n",
              " 'data/alignments/s1/lgas2n.align',\n",
              " 'data/alignments/s1/lgas3s.align',\n",
              " 'data/alignments/s1/lgas4p.align',\n",
              " 'data/alignments/s1/lgas5a.align',\n",
              " 'data/alignments/s1/lgaz6n.align',\n",
              " 'data/alignments/s1/lgaz7s.align',\n",
              " 'data/alignments/s1/lgaz8p.align',\n",
              " 'data/alignments/s1/lgaz9a.align',\n",
              " 'data/alignments/s1/lgbf8n.align',\n",
              " 'data/alignments/s1/lgbf9s.align',\n",
              " 'data/alignments/s1/lgbg1a.align',\n",
              " 'data/alignments/s1/lgbgzp.align',\n",
              " 'data/alignments/s1/lgbm2n.align',\n",
              " 'data/alignments/s1/lgbm3s.align',\n",
              " 'data/alignments/s1/lgbm4p.align',\n",
              " 'data/alignments/s1/lgbm5a.align',\n",
              " 'data/alignments/s1/lgbs6n.align',\n",
              " 'data/alignments/s1/lgbs7s.align',\n",
              " 'data/alignments/s1/lgbs8p.align',\n",
              " 'data/alignments/s1/lgbs9a.align',\n",
              " 'data/alignments/s1/lgif1s.align',\n",
              " 'data/alignments/s1/lgif2p.align',\n",
              " 'data/alignments/s1/lgif3a.align',\n",
              " 'data/alignments/s1/lgifzn.align',\n",
              " 'data/alignments/s1/lgil4n.align',\n",
              " 'data/alignments/s1/lgil5s.align',\n",
              " 'data/alignments/s1/lgil6p.align',\n",
              " 'data/alignments/s1/lgil7a.align',\n",
              " 'data/alignments/s1/lgir8n.align',\n",
              " 'data/alignments/s1/lgir9s.align',\n",
              " 'data/alignments/s1/lgis1a.align',\n",
              " 'data/alignments/s1/lgiszp.align',\n",
              " 'data/alignments/s1/lgiz2n.align',\n",
              " 'data/alignments/s1/lgiz3s.align',\n",
              " 'data/alignments/s1/lgiz4p.align',\n",
              " 'data/alignments/s1/lgiz5a.align',\n",
              " 'data/alignments/s1/lgwa1a.align',\n",
              " 'data/alignments/s1/lgwazp.align',\n",
              " 'data/alignments/s1/lgwg2n.align',\n",
              " 'data/alignments/s1/lgwg3s.align',\n",
              " 'data/alignments/s1/lgwg4p.align',\n",
              " 'data/alignments/s1/lgwg5a.align',\n",
              " 'data/alignments/s1/lgwm6n.align',\n",
              " 'data/alignments/s1/lgwm7s.align',\n",
              " 'data/alignments/s1/lgwm8p.align',\n",
              " 'data/alignments/s1/lgwm9a.align',\n",
              " 'data/alignments/s1/lgwt1s.align',\n",
              " 'data/alignments/s1/lgwt2p.align',\n",
              " 'data/alignments/s1/lgwt3a.align',\n",
              " 'data/alignments/s1/lgwtzn.align',\n",
              " 'data/alignments/s1/lrae2n.align',\n",
              " 'data/alignments/s1/lrae3s.align',\n",
              " 'data/alignments/s1/lrae4p.align',\n",
              " 'data/alignments/s1/lrae5a.align',\n",
              " 'data/alignments/s1/lrak6n.align',\n",
              " 'data/alignments/s1/lrak7s.align',\n",
              " 'data/alignments/s1/lrak8p.align',\n",
              " 'data/alignments/s1/lrak9a.align',\n",
              " 'data/alignments/s1/lrar1s.align',\n",
              " 'data/alignments/s1/lrar2p.align',\n",
              " 'data/alignments/s1/lrar3a.align',\n",
              " 'data/alignments/s1/lrarzn.align',\n",
              " 'data/alignments/s1/lray4n.align',\n",
              " 'data/alignments/s1/lray5s.align',\n",
              " 'data/alignments/s1/lray6p.align',\n",
              " 'data/alignments/s1/lray7a.align',\n",
              " 'data/alignments/s1/lrbe6n.align',\n",
              " 'data/alignments/s1/lrbe7s.align',\n",
              " 'data/alignments/s1/lrbe8p.align',\n",
              " 'data/alignments/s1/lrbe9a.align',\n",
              " 'data/alignments/s1/lrbl1s.align',\n",
              " 'data/alignments/s1/lrbl2p.align',\n",
              " 'data/alignments/s1/lrbl3a.align',\n",
              " 'data/alignments/s1/lrblzn.align',\n",
              " 'data/alignments/s1/lrbr4n.align',\n",
              " 'data/alignments/s1/lrbr5s.align',\n",
              " 'data/alignments/s1/lrbr6p.align',\n",
              " 'data/alignments/s1/lrbr7a.align',\n",
              " 'data/alignments/s1/lrby8n.align',\n",
              " 'data/alignments/s1/lrby9s.align',\n",
              " 'data/alignments/s1/lrbz1a.align',\n",
              " 'data/alignments/s1/lrbzzp.align',\n",
              " 'data/alignments/s1/lrid8n.align',\n",
              " 'data/alignments/s1/lrid9s.align',\n",
              " 'data/alignments/s1/lrie1a.align',\n",
              " 'data/alignments/s1/lriezp.align',\n",
              " 'data/alignments/s1/lrik2n.align',\n",
              " 'data/alignments/s1/lrik3s.align',\n",
              " 'data/alignments/s1/lrik4p.align',\n",
              " 'data/alignments/s1/lrik5a.align',\n",
              " 'data/alignments/s1/lriq6n.align',\n",
              " 'data/alignments/s1/lriq7s.align',\n",
              " 'data/alignments/s1/lriq8p.align',\n",
              " 'data/alignments/s1/lriq9a.align',\n",
              " 'data/alignments/s1/lriy1s.align',\n",
              " 'data/alignments/s1/lriy2p.align',\n",
              " 'data/alignments/s1/lriy3a.align',\n",
              " 'data/alignments/s1/lriyzn.align',\n",
              " 'data/alignments/s1/lrwf1s.align',\n",
              " 'data/alignments/s1/lrwf2p.align',\n",
              " 'data/alignments/s1/lrwf3a.align',\n",
              " 'data/alignments/s1/lrwfzn.align',\n",
              " 'data/alignments/s1/lrwl4n.align',\n",
              " 'data/alignments/s1/lrwl5s.align',\n",
              " 'data/alignments/s1/lrwl6p.align',\n",
              " 'data/alignments/s1/lrwl7a.align',\n",
              " 'data/alignments/s1/lrwr8n.align',\n",
              " 'data/alignments/s1/lrwr9s.align',\n",
              " 'data/alignments/s1/lrws1a.align',\n",
              " 'data/alignments/s1/lrwszp.align',\n",
              " 'data/alignments/s1/lrwz2n.align',\n",
              " 'data/alignments/s1/lrwz3s.align',\n",
              " 'data/alignments/s1/lrwz4p.align',\n",
              " 'data/alignments/s1/lrwz5a.align',\n",
              " 'data/alignments/s1/lwae8n.align',\n",
              " 'data/alignments/s1/lwae9s.align',\n",
              " 'data/alignments/s1/lwaf1a.align',\n",
              " 'data/alignments/s1/lwafzp.align',\n",
              " 'data/alignments/s1/lwal2n.align',\n",
              " 'data/alignments/s1/lwal3s.align',\n",
              " 'data/alignments/s1/lwal4p.align',\n",
              " 'data/alignments/s1/lwal5a.align',\n",
              " 'data/alignments/s1/lwar6n.align',\n",
              " 'data/alignments/s1/lwar7s.align',\n",
              " 'data/alignments/s1/lwar8p.align',\n",
              " 'data/alignments/s1/lwar9a.align',\n",
              " 'data/alignments/s1/lwaz1s.align',\n",
              " 'data/alignments/s1/lwaz2p.align',\n",
              " 'data/alignments/s1/lwaz3a.align',\n",
              " 'data/alignments/s1/lwazzn.align',\n",
              " 'data/alignments/s1/lwbf2n.align',\n",
              " 'data/alignments/s1/lwbf3s.align',\n",
              " 'data/alignments/s1/lwbf4p.align',\n",
              " 'data/alignments/s1/lwbf5a.align',\n",
              " 'data/alignments/s1/lwbl6n.align',\n",
              " 'data/alignments/s1/lwbl7s.align',\n",
              " 'data/alignments/s1/lwbl8p.align',\n",
              " 'data/alignments/s1/lwbl9a.align',\n",
              " 'data/alignments/s1/lwbs1s.align',\n",
              " 'data/alignments/s1/lwbs2p.align',\n",
              " 'data/alignments/s1/lwbs3a.align',\n",
              " 'data/alignments/s1/lwbszn.align',\n",
              " 'data/alignments/s1/lwbz4n.align',\n",
              " 'data/alignments/s1/lwbz5s.align',\n",
              " 'data/alignments/s1/lwbz6p.align',\n",
              " 'data/alignments/s1/lwbz7a.align',\n",
              " 'data/alignments/s1/lwie4n.align',\n",
              " 'data/alignments/s1/lwie5s.align',\n",
              " 'data/alignments/s1/lwie6p.align',\n",
              " 'data/alignments/s1/lwie7a.align',\n",
              " 'data/alignments/s1/lwik8n.align',\n",
              " 'data/alignments/s1/lwik9s.align',\n",
              " 'data/alignments/s1/lwil1a.align',\n",
              " 'data/alignments/s1/lwilzp.align',\n",
              " 'data/alignments/s1/lwir2n.align',\n",
              " 'data/alignments/s1/lwir3s.align',\n",
              " 'data/alignments/s1/lwir4p.align',\n",
              " 'data/alignments/s1/lwir5a.align',\n",
              " 'data/alignments/s1/lwiy6n.align',\n",
              " 'data/alignments/s1/lwiy7s.align',\n",
              " 'data/alignments/s1/lwiy8p.align',\n",
              " 'data/alignments/s1/lwiy9a.align',\n",
              " 'data/alignments/s1/lwwf6n.align',\n",
              " 'data/alignments/s1/lwwf7s.align',\n",
              " 'data/alignments/s1/lwwf8p.align',\n",
              " 'data/alignments/s1/lwwf9a.align',\n",
              " 'data/alignments/s1/lwwm1s.align',\n",
              " 'data/alignments/s1/lwwm2p.align',\n",
              " 'data/alignments/s1/lwwm3a.align',\n",
              " 'data/alignments/s1/lwwmzn.align',\n",
              " 'data/alignments/s1/lwws4n.align',\n",
              " 'data/alignments/s1/lwws5s.align',\n",
              " 'data/alignments/s1/lwws6p.align',\n",
              " 'data/alignments/s1/lwws7a.align',\n",
              " 'data/alignments/s1/lwwz8n.align',\n",
              " 'data/alignments/s1/lwwz9s.align',\n",
              " 'data/alignments/s1/pbac1s.align',\n",
              " 'data/alignments/s1/pbac2p.align',\n",
              " 'data/alignments/s1/pbac3a.align',\n",
              " 'data/alignments/s1/pbaczn.align',\n",
              " 'data/alignments/s1/pbai4n.align',\n",
              " 'data/alignments/s1/pbai5s.align',\n",
              " 'data/alignments/s1/pbai6p.align',\n",
              " 'data/alignments/s1/pbai7a.align',\n",
              " 'data/alignments/s1/pbao8n.align',\n",
              " 'data/alignments/s1/pbao9s.align',\n",
              " 'data/alignments/s1/pbap1a.align',\n",
              " 'data/alignments/s1/pbapzp.align',\n",
              " 'data/alignments/s1/pbav2n.align',\n",
              " 'data/alignments/s1/pbav3s.align',\n",
              " 'data/alignments/s1/pbav4p.align',\n",
              " 'data/alignments/s1/pbav5a.align',\n",
              " 'data/alignments/s1/pbbc4n.align',\n",
              " 'data/alignments/s1/pbbc5s.align',\n",
              " 'data/alignments/s1/pbbc6p.align',\n",
              " 'data/alignments/s1/pbbc7a.align',\n",
              " 'data/alignments/s1/pbbi8n.align',\n",
              " 'data/alignments/s1/pbbi9s.align',\n",
              " 'data/alignments/s1/pbbj1a.align',\n",
              " 'data/alignments/s1/pbbjzp.align',\n",
              " 'data/alignments/s1/pbbp2n.align',\n",
              " 'data/alignments/s1/pbbp3s.align',\n",
              " 'data/alignments/s1/pbbp4p.align',\n",
              " 'data/alignments/s1/pbbp5a.align',\n",
              " 'data/alignments/s1/pbbv6n.align',\n",
              " 'data/alignments/s1/pbbv7s.align',\n",
              " 'data/alignments/s1/pbbv8p.align',\n",
              " 'data/alignments/s1/pbbv9a.align',\n",
              " 'data/alignments/s1/pbib6n.align',\n",
              " 'data/alignments/s1/pbib7s.align',\n",
              " 'data/alignments/s1/pbib8p.align',\n",
              " 'data/alignments/s1/pbib9a.align',\n",
              " 'data/alignments/s1/pbii1s.align',\n",
              " 'data/alignments/s1/pbii2p.align',\n",
              " 'data/alignments/s1/pbii3a.align',\n",
              " 'data/alignments/s1/pbiizn.align',\n",
              " 'data/alignments/s1/pbio4n.align',\n",
              " 'data/alignments/s1/pbio5s.align',\n",
              " 'data/alignments/s1/pbio6p.align',\n",
              " 'data/alignments/s1/pbio7a.align',\n",
              " 'data/alignments/s1/pbiu8n.align',\n",
              " 'data/alignments/s1/pbiu9s.align',\n",
              " 'data/alignments/s1/pbiv1a.align',\n",
              " 'data/alignments/s1/pbivzp.align',\n",
              " 'data/alignments/s1/pbwc8n.align',\n",
              " 'data/alignments/s1/pbwc9s.align',\n",
              " 'data/alignments/s1/pbwd1a.align',\n",
              " 'data/alignments/s1/pbwdzp.align',\n",
              " 'data/alignments/s1/pbwj2n.align',\n",
              " 'data/alignments/s1/pbwj3s.align',\n",
              " 'data/alignments/s1/pbwj4p.align',\n",
              " 'data/alignments/s1/pbwj5a.align',\n",
              " 'data/alignments/s1/pbwp6n.align',\n",
              " 'data/alignments/s1/pbwp7s.align',\n",
              " 'data/alignments/s1/pbwp8p.align',\n",
              " 'data/alignments/s1/pbwp9a.align',\n",
              " 'data/alignments/s1/pbwx1s.align',\n",
              " 'data/alignments/s1/pbwx2p.align',\n",
              " 'data/alignments/s1/pbwx3a.align',\n",
              " 'data/alignments/s1/pbwxzn.align',\n",
              " 'data/alignments/s1/pgad8n.align',\n",
              " 'data/alignments/s1/pgad9s.align',\n",
              " 'data/alignments/s1/pgae1a.align',\n",
              " 'data/alignments/s1/pgaezp.align',\n",
              " 'data/alignments/s1/pgak2n.align',\n",
              " 'data/alignments/s1/pgak3s.align',\n",
              " 'data/alignments/s1/pgak4p.align',\n",
              " 'data/alignments/s1/pgak5a.align',\n",
              " 'data/alignments/s1/pgaq6n.align',\n",
              " 'data/alignments/s1/pgaq7s.align',\n",
              " 'data/alignments/s1/pgaq8p.align',\n",
              " 'data/alignments/s1/pgaq9a.align',\n",
              " 'data/alignments/s1/pgay1s.align',\n",
              " 'data/alignments/s1/pgay2p.align',\n",
              " 'data/alignments/s1/pgay3a.align',\n",
              " 'data/alignments/s1/pgayzn.align',\n",
              " 'data/alignments/s1/pgbe2n.align',\n",
              " 'data/alignments/s1/pgbe3s.align',\n",
              " 'data/alignments/s1/pgbe4p.align',\n",
              " 'data/alignments/s1/pgbe5a.align',\n",
              " 'data/alignments/s1/pgbk6n.align',\n",
              " 'data/alignments/s1/pgbk7s.align',\n",
              " 'data/alignments/s1/pgbk8p.align',\n",
              " 'data/alignments/s1/pgbk9a.align',\n",
              " 'data/alignments/s1/pgbr1s.align',\n",
              " 'data/alignments/s1/pgbr2p.align',\n",
              " 'data/alignments/s1/pgbr3a.align',\n",
              " 'data/alignments/s1/pgbrzn.align',\n",
              " 'data/alignments/s1/pgby4n.align',\n",
              " 'data/alignments/s1/pgby5s.align',\n",
              " 'data/alignments/s1/pgby6p.align',\n",
              " 'data/alignments/s1/pgby7a.align',\n",
              " 'data/alignments/s1/pgid4n.align',\n",
              " 'data/alignments/s1/pgid5s.align',\n",
              " 'data/alignments/s1/pgid6p.align',\n",
              " 'data/alignments/s1/pgid7a.align',\n",
              " 'data/alignments/s1/pgij8n.align',\n",
              " 'data/alignments/s1/pgij9s.align',\n",
              " 'data/alignments/s1/pgik1a.align',\n",
              " 'data/alignments/s1/pgikzp.align',\n",
              " 'data/alignments/s1/pgiq2n.align',\n",
              " 'data/alignments/s1/pgiq3s.align',\n",
              " 'data/alignments/s1/pgiq4p.align',\n",
              " 'data/alignments/s1/pgiq5a.align',\n",
              " 'data/alignments/s1/pgix6n.align',\n",
              " 'data/alignments/s1/pgix7s.align',\n",
              " 'data/alignments/s1/pgix8p.align',\n",
              " 'data/alignments/s1/pgix9a.align',\n",
              " 'data/alignments/s1/pgwe6n.align',\n",
              " 'data/alignments/s1/pgwe7s.align',\n",
              " 'data/alignments/s1/pgwe8p.align',\n",
              " 'data/alignments/s1/pgwe9a.align',\n",
              " 'data/alignments/s1/pgwl1s.align',\n",
              " 'data/alignments/s1/pgwl2p.align',\n",
              " 'data/alignments/s1/pgwl3a.align',\n",
              " 'data/alignments/s1/pgwlzn.align',\n",
              " 'data/alignments/s1/pgwr4n.align',\n",
              " 'data/alignments/s1/pgwr5s.align',\n",
              " 'data/alignments/s1/pgwr6p.align',\n",
              " 'data/alignments/s1/pgwr7a.align',\n",
              " 'data/alignments/s1/pgwy8n.align',\n",
              " 'data/alignments/s1/pgwy9s.align',\n",
              " 'data/alignments/s1/pgwz1a.align',\n",
              " 'data/alignments/s1/pgwzzp.align',\n",
              " 'data/alignments/s1/prac6n.align',\n",
              " 'data/alignments/s1/prac7s.align',\n",
              " 'data/alignments/s1/prac8p.align',\n",
              " 'data/alignments/s1/prac9a.align',\n",
              " 'data/alignments/s1/praj1s.align',\n",
              " 'data/alignments/s1/praj2p.align',\n",
              " 'data/alignments/s1/praj3a.align',\n",
              " 'data/alignments/s1/prajzn.align',\n",
              " 'data/alignments/s1/prap4n.align',\n",
              " 'data/alignments/s1/prap5s.align',\n",
              " 'data/alignments/s1/prap6p.align',\n",
              " 'data/alignments/s1/prap7a.align',\n",
              " 'data/alignments/s1/prav8n.align',\n",
              " 'data/alignments/s1/prav9s.align',\n",
              " 'data/alignments/s1/prax1a.align',\n",
              " 'data/alignments/s1/praxzp.align',\n",
              " 'data/alignments/s1/prbd1s.align',\n",
              " 'data/alignments/s1/prbd2p.align',\n",
              " 'data/alignments/s1/prbd3a.align',\n",
              " 'data/alignments/s1/prbdzn.align',\n",
              " 'data/alignments/s1/prbj4n.align',\n",
              " 'data/alignments/s1/prbj5s.align',\n",
              " 'data/alignments/s1/prbj6p.align',\n",
              " 'data/alignments/s1/prbj7a.align',\n",
              " 'data/alignments/s1/prbp8n.align',\n",
              " 'data/alignments/s1/prbp9s.align',\n",
              " 'data/alignments/s1/prbq1a.align',\n",
              " 'data/alignments/s1/prbqzp.align',\n",
              " 'data/alignments/s1/prbx2n.align',\n",
              " 'data/alignments/s1/prbx3s.align',\n",
              " 'data/alignments/s1/prbx4p.align',\n",
              " 'data/alignments/s1/prbx5a.align',\n",
              " 'data/alignments/s1/pric2n.align',\n",
              " 'data/alignments/s1/pric3s.align',\n",
              " 'data/alignments/s1/pric4p.align',\n",
              " 'data/alignments/s1/pric5a.align',\n",
              " 'data/alignments/s1/prii6n.align',\n",
              " 'data/alignments/s1/prii7s.align',\n",
              " 'data/alignments/s1/prii8p.align',\n",
              " 'data/alignments/s1/prii9a.align',\n",
              " 'data/alignments/s1/prip1s.align',\n",
              " 'data/alignments/s1/prip2p.align',\n",
              " 'data/alignments/s1/prip3a.align',\n",
              " 'data/alignments/s1/pripzn.align',\n",
              " 'data/alignments/s1/priv4n.align',\n",
              " 'data/alignments/s1/priv5s.align',\n",
              " 'data/alignments/s1/priv6p.align',\n",
              " 'data/alignments/s1/priv7a.align',\n",
              " 'data/alignments/s1/prwd4n.align',\n",
              " 'data/alignments/s1/prwd5s.align',\n",
              " 'data/alignments/s1/prwd6p.align',\n",
              " 'data/alignments/s1/prwd7a.align',\n",
              " 'data/alignments/s1/prwj8n.align',\n",
              " 'data/alignments/s1/prwj9s.align',\n",
              " 'data/alignments/s1/prwk1a.align',\n",
              " 'data/alignments/s1/prwkzp.align',\n",
              " 'data/alignments/s1/prwq2n.align',\n",
              " 'data/alignments/s1/prwq3s.align',\n",
              " 'data/alignments/s1/prwq4p.align',\n",
              " 'data/alignments/s1/prwq5a.align',\n",
              " 'data/alignments/s1/prwx6n.align',\n",
              " 'data/alignments/s1/prwx7s.align',\n",
              " 'data/alignments/s1/prwx8p.align',\n",
              " 'data/alignments/s1/prwx9a.align',\n",
              " 'data/alignments/s1/pwad2n.align',\n",
              " 'data/alignments/s1/pwad3s.align',\n",
              " 'data/alignments/s1/pwad4p.align',\n",
              " 'data/alignments/s1/pwad5a.align',\n",
              " 'data/alignments/s1/pwaj6n.align',\n",
              " 'data/alignments/s1/pwaj7s.align',\n",
              " 'data/alignments/s1/pwaj8p.align',\n",
              " 'data/alignments/s1/pwaj9a.align',\n",
              " 'data/alignments/s1/pwaq1s.align',\n",
              " 'data/alignments/s1/pwaq2p.align',\n",
              " 'data/alignments/s1/pwaq3a.align',\n",
              " 'data/alignments/s1/pwaqzn.align',\n",
              " 'data/alignments/s1/pwax4n.align',\n",
              " 'data/alignments/s1/pwax5s.align',\n",
              " 'data/alignments/s1/pwax6p.align',\n",
              " 'data/alignments/s1/pwax7a.align',\n",
              " 'data/alignments/s1/pwbd6n.align',\n",
              " 'data/alignments/s1/pwbd7s.align',\n",
              " 'data/alignments/s1/pwbd8p.align',\n",
              " 'data/alignments/s1/pwbd9a.align',\n",
              " 'data/alignments/s1/pwbk1s.align',\n",
              " 'data/alignments/s1/pwbk2p.align',\n",
              " 'data/alignments/s1/pwbk3a.align',\n",
              " 'data/alignments/s1/pwbkzn.align',\n",
              " 'data/alignments/s1/pwbq4n.align',\n",
              " 'data/alignments/s1/pwbq5s.align',\n",
              " 'data/alignments/s1/pwbq6p.align',\n",
              " 'data/alignments/s1/pwbq7a.align',\n",
              " 'data/alignments/s1/pwbx8n.align',\n",
              " 'data/alignments/s1/pwbx9s.align',\n",
              " 'data/alignments/s1/pwby1a.align',\n",
              " 'data/alignments/s1/pwbyzp.align',\n",
              " 'data/alignments/s1/pwic8n.align',\n",
              " 'data/alignments/s1/pwic9s.align',\n",
              " 'data/alignments/s1/pwid1a.align',\n",
              " 'data/alignments/s1/pwidzp.align',\n",
              " 'data/alignments/s1/pwij2n.align',\n",
              " 'data/alignments/s1/pwij3s.align',\n",
              " 'data/alignments/s1/pwij4p.align',\n",
              " 'data/alignments/s1/pwij5a.align',\n",
              " 'data/alignments/s1/pwip6n.align',\n",
              " 'data/alignments/s1/pwip7s.align',\n",
              " 'data/alignments/s1/pwip8p.align',\n",
              " 'data/alignments/s1/pwip9a.align',\n",
              " 'data/alignments/s1/pwix1s.align',\n",
              " 'data/alignments/s1/pwix2p.align',\n",
              " 'data/alignments/s1/pwix3a.align',\n",
              " 'data/alignments/s1/pwixzn.align',\n",
              " 'data/alignments/s1/pwwe1s.align',\n",
              " 'data/alignments/s1/pwwe2p.align',\n",
              " 'data/alignments/s1/pwwe3a.align',\n",
              " 'data/alignments/s1/pwwezn.align',\n",
              " 'data/alignments/s1/pwwk4n.align',\n",
              " 'data/alignments/s1/pwwk5s.align',\n",
              " 'data/alignments/s1/pwwk6p.align',\n",
              " 'data/alignments/s1/pwwk7a.align',\n",
              " 'data/alignments/s1/pwwq8n.align',\n",
              " 'data/alignments/s1/pwwq9s.align',\n",
              " 'data/alignments/s1/pwwr1a.align',\n",
              " 'data/alignments/s1/pwwrzp.align',\n",
              " 'data/alignments/s1/pwwy2n.align',\n",
              " 'data/alignments/s1/pwwy3s.align',\n",
              " 'data/alignments/s1/pwwy4p.align',\n",
              " 'data/alignments/s1/pwwy5a.align',\n",
              " 'data/alignments/s1/sbaa4n.align',\n",
              " 'data/alignments/s1/sbaa5s.align',\n",
              " 'data/alignments/s1/sbaa6p.align',\n",
              " 'data/alignments/s1/sbaa7a.align',\n",
              " 'data/alignments/s1/sbag8n.align',\n",
              " 'data/alignments/s1/sbag9s.align',\n",
              " 'data/alignments/s1/sbah1a.align',\n",
              " 'data/alignments/s1/sbahzp.align',\n",
              " 'data/alignments/s1/sban2n.align',\n",
              " 'data/alignments/s1/sban3s.align',\n",
              " 'data/alignments/s1/sban4p.align',\n",
              " 'data/alignments/s1/sban5a.align',\n",
              " 'data/alignments/s1/sbat6n.align',\n",
              " 'data/alignments/s1/sbat7s.align',\n",
              " 'data/alignments/s1/sbat8p.align',\n",
              " 'data/alignments/s1/sbat9a.align',\n",
              " 'data/alignments/s1/sbba8n.align',\n",
              " 'data/alignments/s1/sbba9s.align',\n",
              " 'data/alignments/s1/sbbb1a.align',\n",
              " 'data/alignments/s1/sbbbzp.align',\n",
              " 'data/alignments/s1/sbbh2n.align',\n",
              " 'data/alignments/s1/sbbh3s.align',\n",
              " 'data/alignments/s1/sbbh4p.align',\n",
              " 'data/alignments/s1/sbbh5a.align',\n",
              " 'data/alignments/s1/sbbn6n.align',\n",
              " 'data/alignments/s1/sbbn7s.align',\n",
              " 'data/alignments/s1/sbbn8p.align',\n",
              " 'data/alignments/s1/sbbn9a.align',\n",
              " 'data/alignments/s1/sbbu1s.align',\n",
              " 'data/alignments/s1/sbbu2p.align',\n",
              " 'data/alignments/s1/sbbu3a.align',\n",
              " 'data/alignments/s1/sbbuzn.align',\n",
              " 'data/alignments/s1/sbia1s.align',\n",
              " 'data/alignments/s1/sbia2p.align',\n",
              " 'data/alignments/s1/sbia3a.align',\n",
              " 'data/alignments/s1/sbiazn.align',\n",
              " 'data/alignments/s1/sbig4n.align',\n",
              " 'data/alignments/s1/sbig5s.align',\n",
              " 'data/alignments/s1/sbig6p.align',\n",
              " 'data/alignments/s1/sbig7a.align',\n",
              " 'data/alignments/s1/sbim8n.align',\n",
              " 'data/alignments/s1/sbim9s.align',\n",
              " 'data/alignments/s1/sbin1a.align',\n",
              " 'data/alignments/s1/sbinzp.align',\n",
              " 'data/alignments/s1/sbit2n.align',\n",
              " 'data/alignments/s1/sbit3s.align',\n",
              " 'data/alignments/s1/sbit4p.align',\n",
              " 'data/alignments/s1/sbit5a.align',\n",
              " 'data/alignments/s1/sbwb2n.align',\n",
              " 'data/alignments/s1/sbwb3s.align',\n",
              " 'data/alignments/s1/sbwb4p.align',\n",
              " 'data/alignments/s1/sbwb5a.align',\n",
              " 'data/alignments/s1/sbwh6n.align',\n",
              " 'data/alignments/s1/sbwh7s.align',\n",
              " 'data/alignments/s1/sbwh8p.align',\n",
              " 'data/alignments/s1/sbwh9a.align',\n",
              " 'data/alignments/s1/sbwo1s.align',\n",
              " 'data/alignments/s1/sbwo2p.align',\n",
              " 'data/alignments/s1/sbwo3a.align',\n",
              " 'data/alignments/s1/sbwozn.align',\n",
              " 'data/alignments/s1/sbwu4n.align',\n",
              " 'data/alignments/s1/sbwu5s.align',\n",
              " 'data/alignments/s1/sbwu6p.align',\n",
              " 'data/alignments/s1/sbwu7a.align',\n",
              " 'data/alignments/s1/sgac2n.align',\n",
              " 'data/alignments/s1/sgac3s.align',\n",
              " 'data/alignments/s1/sgac4p.align',\n",
              " 'data/alignments/s1/sgac5a.align',\n",
              " 'data/alignments/s1/sgai6n.align',\n",
              " 'data/alignments/s1/sgai7s.align',\n",
              " 'data/alignments/s1/sgai8p.align',\n",
              " 'data/alignments/s1/sgai9a.align',\n",
              " 'data/alignments/s1/sgap1s.align',\n",
              " 'data/alignments/s1/sgap2p.align',\n",
              " 'data/alignments/s1/sgap3a.align',\n",
              " 'data/alignments/s1/sgapzn.align',\n",
              " 'data/alignments/s1/sgav4n.align',\n",
              " 'data/alignments/s1/sgav5s.align',\n",
              " 'data/alignments/s1/sgav6p.align',\n",
              " 'data/alignments/s1/sgav7a.align',\n",
              " 'data/alignments/s1/sgbc6n.align',\n",
              " 'data/alignments/s1/sgbc7s.align',\n",
              " 'data/alignments/s1/sgbc8p.align',\n",
              " 'data/alignments/s1/sgbc9a.align',\n",
              " 'data/alignments/s1/sgbj1s.align',\n",
              " 'data/alignments/s1/sgbj2p.align',\n",
              " 'data/alignments/s1/sgbj3a.align',\n",
              " 'data/alignments/s1/sgbjzn.align',\n",
              " 'data/alignments/s1/sgbp4n.align',\n",
              " 'data/alignments/s1/sgbp5s.align',\n",
              " 'data/alignments/s1/sgbp6p.align',\n",
              " 'data/alignments/s1/sgbp7a.align',\n",
              " 'data/alignments/s1/sgbv8n.align',\n",
              " 'data/alignments/s1/sgbv9s.align',\n",
              " 'data/alignments/s1/sgbx1a.align',\n",
              " 'data/alignments/s1/sgbxzp.align',\n",
              " 'data/alignments/s1/sgib8n.align',\n",
              " 'data/alignments/s1/sgib9s.align',\n",
              " 'data/alignments/s1/sgic1a.align',\n",
              " 'data/alignments/s1/sgiczp.align',\n",
              " 'data/alignments/s1/sgii2n.align',\n",
              " 'data/alignments/s1/sgii3s.align',\n",
              " 'data/alignments/s1/sgii4p.align',\n",
              " 'data/alignments/s1/sgii5a.align',\n",
              " 'data/alignments/s1/sgio6n.align',\n",
              " 'data/alignments/s1/sgio7s.align',\n",
              " 'data/alignments/s1/sgio8p.align',\n",
              " 'data/alignments/s1/sgio9a.align',\n",
              " 'data/alignments/s1/sgiv1s.align',\n",
              " 'data/alignments/s1/sgiv2p.align',\n",
              " 'data/alignments/s1/sgiv3a.align',\n",
              " 'data/alignments/s1/sgivzn.align',\n",
              " 'data/alignments/s1/sgwd1s.align',\n",
              " 'data/alignments/s1/sgwd2p.align',\n",
              " 'data/alignments/s1/sgwd3a.align',\n",
              " 'data/alignments/s1/sgwdzn.align',\n",
              " 'data/alignments/s1/sgwj4n.align',\n",
              " 'data/alignments/s1/sgwj5s.align',\n",
              " 'data/alignments/s1/sgwj6p.align',\n",
              " 'data/alignments/s1/sgwj7a.align',\n",
              " 'data/alignments/s1/sgwp8n.align',\n",
              " 'data/alignments/s1/sgwp9s.align',\n",
              " 'data/alignments/s1/sgwq1a.align',\n",
              " 'data/alignments/s1/sgwqzp.align',\n",
              " 'data/alignments/s1/sgwx2n.align',\n",
              " 'data/alignments/s1/sgwx3s.align',\n",
              " 'data/alignments/s1/sgwx4p.align',\n",
              " 'data/alignments/s1/sgwx5a.align',\n",
              " 'data/alignments/s1/srab1s.align',\n",
              " 'data/alignments/s1/srab2p.align',\n",
              " 'data/alignments/s1/srab3a.align',\n",
              " 'data/alignments/s1/srabzn.align',\n",
              " 'data/alignments/s1/srah4n.align',\n",
              " 'data/alignments/s1/srah5s.align',\n",
              " 'data/alignments/s1/srah6p.align',\n",
              " 'data/alignments/s1/srah7a.align',\n",
              " 'data/alignments/s1/sran8n.align',\n",
              " 'data/alignments/s1/sran9s.align',\n",
              " 'data/alignments/s1/srao1a.align',\n",
              " 'data/alignments/s1/sraozp.align',\n",
              " 'data/alignments/s1/srau2n.align',\n",
              " 'data/alignments/s1/srau3s.align',\n",
              " 'data/alignments/s1/srau4p.align',\n",
              " 'data/alignments/s1/srau5a.align',\n",
              " 'data/alignments/s1/srbb4n.align',\n",
              " 'data/alignments/s1/srbb5s.align',\n",
              " 'data/alignments/s1/srbb6p.align',\n",
              " 'data/alignments/s1/srbb7a.align',\n",
              " 'data/alignments/s1/srbh8n.align',\n",
              " 'data/alignments/s1/srbh9s.align',\n",
              " 'data/alignments/s1/srbi1a.align',\n",
              " 'data/alignments/s1/srbizp.align',\n",
              " 'data/alignments/s1/srbo2n.align',\n",
              " 'data/alignments/s1/srbo3s.align',\n",
              " 'data/alignments/s1/srbo4p.align',\n",
              " 'data/alignments/s1/srbo5a.align',\n",
              " 'data/alignments/s1/srbu6n.align',\n",
              " 'data/alignments/s1/srbu7s.align',\n",
              " 'data/alignments/s1/srbu8p.align',\n",
              " 'data/alignments/s1/srbu9a.align',\n",
              " 'data/alignments/s1/sria6n.align',\n",
              " 'data/alignments/s1/sria7s.align',\n",
              " 'data/alignments/s1/sria8p.align',\n",
              " 'data/alignments/s1/sria9a.align',\n",
              " 'data/alignments/s1/srih1s.align',\n",
              " 'data/alignments/s1/srih2p.align',\n",
              " 'data/alignments/s1/srih3a.align',\n",
              " 'data/alignments/s1/srihzn.align',\n",
              " 'data/alignments/s1/srin4n.align',\n",
              " 'data/alignments/s1/srin5s.align',\n",
              " 'data/alignments/s1/srin6p.align',\n",
              " 'data/alignments/s1/srin7a.align',\n",
              " 'data/alignments/s1/srit8n.align',\n",
              " 'data/alignments/s1/srit9s.align',\n",
              " 'data/alignments/s1/sriu1a.align',\n",
              " 'data/alignments/s1/sriuzp.align',\n",
              " 'data/alignments/s1/srwb8n.align',\n",
              " 'data/alignments/s1/srwb9s.align',\n",
              " 'data/alignments/s1/srwc1a.align',\n",
              " 'data/alignments/s1/srwczp.align',\n",
              " 'data/alignments/s1/srwi2n.align',\n",
              " 'data/alignments/s1/srwi3s.align',\n",
              " 'data/alignments/s1/srwi4p.align',\n",
              " 'data/alignments/s1/srwi5a.align',\n",
              " 'data/alignments/s1/srwo6n.align',\n",
              " 'data/alignments/s1/srwo7s.align',\n",
              " 'data/alignments/s1/srwo8p.align',\n",
              " 'data/alignments/s1/srwo9a.align',\n",
              " 'data/alignments/s1/srwv1s.align',\n",
              " 'data/alignments/s1/srwv2p.align',\n",
              " 'data/alignments/s1/srwv3a.align',\n",
              " 'data/alignments/s1/srwvzn.align',\n",
              " 'data/alignments/s1/swab6n.align',\n",
              " 'data/alignments/s1/swab7s.align',\n",
              " 'data/alignments/s1/swab8p.align',\n",
              " 'data/alignments/s1/swab9a.align',\n",
              " 'data/alignments/s1/swai1s.align',\n",
              " 'data/alignments/s1/swai2p.align',\n",
              " 'data/alignments/s1/swai3a.align',\n",
              " 'data/alignments/s1/swaizn.align',\n",
              " 'data/alignments/s1/swao4n.align',\n",
              " 'data/alignments/s1/swao5s.align',\n",
              " 'data/alignments/s1/swao6p.align',\n",
              " 'data/alignments/s1/swao7a.align',\n",
              " 'data/alignments/s1/swau8n.align',\n",
              " 'data/alignments/s1/swau9s.align',\n",
              " 'data/alignments/s1/swav1a.align',\n",
              " 'data/alignments/s1/swavzp.align',\n",
              " 'data/alignments/s1/swbc1s.align',\n",
              " 'data/alignments/s1/swbc2p.align',\n",
              " 'data/alignments/s1/swbc3a.align',\n",
              " 'data/alignments/s1/swbczn.align',\n",
              " 'data/alignments/s1/swbi4n.align',\n",
              " 'data/alignments/s1/swbi5s.align',\n",
              " 'data/alignments/s1/swbi6p.align',\n",
              " 'data/alignments/s1/swbi7a.align',\n",
              " 'data/alignments/s1/swbo8n.align',\n",
              " 'data/alignments/s1/swbo9s.align',\n",
              " 'data/alignments/s1/swbp1a.align',\n",
              " 'data/alignments/s1/swbpzp.align',\n",
              " 'data/alignments/s1/swbv2n.align',\n",
              " 'data/alignments/s1/swbv3s.align',\n",
              " 'data/alignments/s1/swbv4p.align',\n",
              " 'data/alignments/s1/swbv5a.align',\n",
              " 'data/alignments/s1/swib2n.align',\n",
              " 'data/alignments/s1/swib3s.align',\n",
              " 'data/alignments/s1/swib4p.align',\n",
              " 'data/alignments/s1/swib5a.align',\n",
              " 'data/alignments/s1/swih6n.align',\n",
              " 'data/alignments/s1/swih7s.align',\n",
              " 'data/alignments/s1/swih8p.align',\n",
              " 'data/alignments/s1/swih9a.align',\n",
              " 'data/alignments/s1/swio1s.align',\n",
              " 'data/alignments/s1/swio2p.align',\n",
              " 'data/alignments/s1/swio3a.align',\n",
              " 'data/alignments/s1/swiozn.align',\n",
              " 'data/alignments/s1/swiu4n.align',\n",
              " 'data/alignments/s1/swiu5s.align',\n",
              " 'data/alignments/s1/swiu6p.align',\n",
              " 'data/alignments/s1/swiu7a.align',\n",
              " 'data/alignments/s1/swwc4n.align',\n",
              " 'data/alignments/s1/swwc5s.align',\n",
              " 'data/alignments/s1/swwc6p.align',\n",
              " 'data/alignments/s1/swwc7a.align',\n",
              " 'data/alignments/s1/swwi8n.align',\n",
              " 'data/alignments/s1/swwi9s.align',\n",
              " 'data/alignments/s1/swwj1a.align',\n",
              " 'data/alignments/s1/swwjzp.align',\n",
              " 'data/alignments/s1/swwp2n.align',\n",
              " 'data/alignments/s1/swwp3s.align',\n",
              " 'data/alignments/s1/swwp4p.align',\n",
              " 'data/alignments/s1/swwp5a.align',\n",
              " 'data/alignments/s1/swwv6n.align',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "'''\n",
        "  Download a part of dataset for representation purpose of working of the pipeline.\n",
        "  The original dataset contains multiple speakers (34), but for the ease of training\n",
        "  and computational limitations, we are considering only 2 speakers, consisting of 1000 videos,\n",
        "  out of which 900 is in training and 100 is in testing partition.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
        "output_file = 'data.zip'\n",
        "\n",
        "gdown.download(url, output_file, quiet=False)\n",
        "gdown.extractall('data.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RxwKJvGQwTd6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Creating the custom video loader to preprocess the video frames.\n",
        "  It loads a video, extracts frames, converts to grayscale, crops the lip region,\n",
        "  and standardizes the pixel values.\n",
        "\n",
        "'''\n",
        "\n",
        "def load_video(path: str) -> torch.Tensor:\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Placeholder to apply DLip Detector (Have to add it here)\n",
        "\n",
        "        mouth_crop = frame[190:240, 100:200] # Results in 50x100\n",
        "        mouth_crop_resized = cv2.resize(mouth_crop, (100, 50))\n",
        "\n",
        "        frames.append(mouth_crop_resized)\n",
        "    cap.release()\n",
        "\n",
        "    frames_np = np.stack(frames)\n",
        "\n",
        "    frames_np = frames_np[..., ::-1].copy() # BGR -> RGB\n",
        "    frames_tensor = torch.from_numpy(frames_np).float()\n",
        "\n",
        "    mean = frames_tensor.mean(dim=(0, 1, 2))\n",
        "    std = frames_tensor.std(dim=(0, 1, 2))\n",
        "    standardized_frames = (frames_tensor - mean) / (std + 1e-6)\n",
        "\n",
        "    # Return shape (T, H, W, C)\n",
        "    return standardized_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b9TVxe19wTbM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Declaring Vocabulary\n",
        "\n",
        "'''\n",
        "\n",
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz \"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieEGs20KwTYo",
        "outputId": "58d04444-c930-42fb-e4a2-c0ed4db8de15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' '] (size =28)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  Creating dictionary of vocab to map to numerical values.\n",
        "\n",
        "'''\n",
        "\n",
        "vocab_full = [''] + vocab   # Adding the out-of-vocabulary token\n",
        "\n",
        "char_to_num = {char: i for i, char in enumerate(vocab_full)}\n",
        "\n",
        "num_to_char = {i: char for i, char in enumerate(vocab_full)}\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {vocab_full} \"\n",
        "    f\"(size ={len(vocab_full)})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VqwPqpvXwTV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b9e409-6212-454b-8783-5acd62c0cacb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "vocab_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "414w51tjwTTT",
        "outputId": "eea3a34e-120e-4e86-c744-ca0f1460e4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([25, 21,  7, 27,  2,  1, 18,  7,  1, 23,  1, 25])\n"
          ]
        }
      ],
      "source": [
        "name = ['y', 'u', 'g', ' ', 'b', 'a', 'r', 'g', 'a', 'w', 'a', 'y']\n",
        "\n",
        "idx = [char_to_num[char] for char in name]\n",
        "\n",
        "idx_tsr = torch.tensor(idx)\n",
        "\n",
        "print(idx_tsr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARHEFyJix5Fz",
        "outputId": "52827540-4935-4eab-8e2e-df1ccac8320c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['y', 'u', 'g', ' ', 'b', 'a', 'r', 'g', 'a', 'w', 'a', 'y']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ch = [num_to_char[i] for i in [25, 21,  7, 27,  2,  1, 18,  7,  1, 23,  1, 25]]\n",
        "\n",
        "print(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HkQVOBd5x5DA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Load transcripts of video and tokenize it accordingly\n",
        "  It reads an alignment file, extracts the words, converts them to a sequence\n",
        "  of character indices, and returns them as a tensor.\n",
        "\n",
        "'''\n",
        "\n",
        "def load_alignments(path: str) -> torch.Tensor:\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    words = [line.split()[2] for line in lines if line.split()[2] != 'sil']   # Ignore silence\n",
        "    text = ' '.join(words)\n",
        "    tokens = [char_to_num[char] for char in text]\n",
        "\n",
        "    return torch.tensor(tokens, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MqZIJPSqx5At"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Complete data loader function, which loads the video and maps it with its corresponding transcript.\n",
        "  It takes a file path to an mpg video, constructs the corresponding alignment path,\n",
        "  and loads both the video frames and alignment tokens.\n",
        "\n",
        "'''\n",
        "\n",
        "def load_data(path: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    bs = os.path.basename(path)   # file name\n",
        "    file_name, _ = os.path.splitext(bs)\n",
        "\n",
        "    video_path = os.path.join('data', 's1', f'{file_name}.mpg')\n",
        "    alignment_path = os.path.join('data', 'alignments', 's1', f'{file_name}.align')\n",
        "\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O4S3QkkIx4-f"
      },
      "outputs": [],
      "source": [
        "test_path = './data/s1/bbal6n.mpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5glJngEhx48Y",
        "outputId": "95c582c1-f8d9-4e0a-a9bb-951058598714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbal6n\n"
          ]
        }
      ],
      "source": [
        "file_name = os.path.splitext(os.path.basename(test_path))[0]\n",
        "\n",
        "print(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v5U3kRoyx45e"
      },
      "outputs": [],
      "source": [
        "frames, alignments = load_data(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "E9miQGXYx43T",
        "outputId": "67d96ef5-e3d7-4e21-ab66-fe22b9b75acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-3.0614226..2.4073422].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78ecd6629b80>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(frames.numpy()[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvX3XPjDx40v",
        "outputId": "0e84f300-75b0-4764-9e54-3002db88e31a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  9, 14, 27,  2, 12, 21,  5, 27,  1, 20, 27, 12, 27, 19,  9, 24, 27,\n",
              "        14, 15, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGfXjggQx4yQ",
        "outputId": "7a8f7a87-3422-4c7b-bae4-d84f6768404d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin blue at l six now\n"
          ]
        }
      ],
      "source": [
        "text = ''.join([num_to_char[i.item()] for i in alignments])\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQ57naTBS4s_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iqCmcZnS4qO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dmuCFj2kx4vy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwxkGh1p0Hho"
      },
      "source": [
        "## 1.2 Creating Data Pipeline\n",
        "Creating a neural network is great, but having a structured data pipeline helps in structured training and increasing the amount of training data we are using at any point for a better model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "znn9_AOC0G-2"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CcSeBqg0x4tM"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "'''\n",
        "  PyTorch Dataset class to fetch items and other operation requirements.\n",
        "\n",
        "'''\n",
        "\n",
        "class LipNetDataset(Dataset):\n",
        "    def __init__(self, data_dir='./data/s1/*.mpg'):\n",
        "        self.file_paths = glob.glob(data_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_paths[idx]\n",
        "\n",
        "        frames, alignments = load_data(path)\n",
        "        return frames, alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yQ-QMb0Dz5wW"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "'''\n",
        "  For a complete batch of items, we need to pad the items accordingly and return processed items.\n",
        "\n",
        "'''\n",
        "\n",
        "def collate_fn(batch):\n",
        "    frames, alignments = zip(*batch)\n",
        "\n",
        "    frame_lengths = torch.tensor([f.shape[0] for f in frames])\n",
        "    alignment_lengths = torch.tensor([len(a) for a in alignments])\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_frames = pad_sequence(frames, batch_first=True, padding_value=0)\n",
        "    padded_alignments = pad_sequence(alignments, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Permute to (N, C, T, H, W) for Conv3D\n",
        "    padded_frames = padded_frames.permute(0, 4, 1, 2, 3)\n",
        "\n",
        "    return padded_frames, padded_alignments, frame_lengths, alignment_lengths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtDbaXjhz5ti",
        "outputId": "77dcc4d8-522a-4cf5-da5c-a8dde7d67e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 1000\n",
            "Training samples: 900\n",
            "Testing samples: 100\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "'''\n",
        "  Creating train and test dataloader to facililate the training and testing process\n",
        "\n",
        "'''\n",
        "\n",
        "full_dataset = LipNetDataset()\n",
        "\n",
        "train_size = 900\n",
        "test_size = 100\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(full_dataset)}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Testing samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "k9btRsO2z5rA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADoN69Khz5os",
        "outputId": "e3322f00-aa09-4662-e375-5481b4e72111"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmIxg0Hjz5mE",
        "outputId": "55624efa-22f9-4466-d079-67c1417f9dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames tensor shape: torch.Size([8, 3, 75, 50, 100])\n",
            "Frames tensor dtype: torch.float32\n",
            "Alignments tensor shape: torch.Size([8, 30])\n",
            "Alignments tensor dtype: torch.int64\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  Creating an iterator from train_loader dataloader\n",
        "\n",
        "'''\n",
        "\n",
        "data_iterator = iter(train_loader)\n",
        "\n",
        "frames, alignments, _, _ = next(data_iterator)\n",
        "\n",
        "print(f\"Frames tensor shape: {frames.shape}\")\n",
        "print(f\"Frames tensor dtype: {frames.dtype}\")\n",
        "print(f\"Alignments tensor shape: {alignments.shape}\")\n",
        "print(f\"Alignments tensor dtype: {alignments.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnBxHA-Pz5jf",
        "outputId": "fefa41f9-35f8-4788-b08c-23193d63f7da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "len(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1qFOewlNz5gw"
      },
      "outputs": [],
      "source": [
        "sample_iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV01f-voz5eV",
        "outputId": "d5b1dc51-0f78-4cb8-a3bc-9ef9d8946162"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[[ 0.6292,  0.9407,  1.2967,  ...,  0.2955, -0.6390, -0.9949],\n",
              "           [ 0.5847,  0.9407,  1.3634,  ...,  0.2955, -0.6390, -1.0394],\n",
              "           [-0.1272,  0.4957,  1.2522,  ..., -0.1272, -1.5734, -1.8404],\n",
              "           ...,\n",
              "           [-1.4622, -1.8181, -2.1074,  ..., -3.0863, -2.8861, -2.6191],\n",
              "           [-1.4622, -1.8404, -2.1964,  ..., -3.0418, -2.8638, -2.7081],\n",
              "           [-1.4622, -1.9071, -2.2409,  ..., -3.0418, -2.8638, -2.7971]],\n",
              "\n",
              "          [[ 0.7850,  1.0074,  1.2299,  ...,  0.2955, -0.5945, -1.0617],\n",
              "           [ 0.6960,  1.0074,  1.2522,  ...,  0.2732, -0.6390, -1.1729],\n",
              "           [-0.2385,  0.5847,  1.3189,  ..., -0.0382, -1.2397, -1.7291],\n",
              "           ...,\n",
              "           [-1.6401, -1.8626, -2.1296,  ..., -2.9751, -2.9083, -2.6858],\n",
              "           [-1.5734, -1.8849, -2.1964,  ..., -2.9751, -2.9306, -2.8861],\n",
              "           [-1.5067, -1.9516, -2.2631,  ..., -3.0418, -2.9751, -2.9083]],\n",
              "\n",
              "          [[ 0.8517,  1.0297,  1.2299,  ...,  0.3622, -0.5722, -1.0839],\n",
              "           [ 0.6960,  1.0742,  1.3412,  ...,  0.3400, -0.6167, -1.1952],\n",
              "           [-0.1272,  0.6070,  1.3189,  ...,  0.0507, -1.1729, -1.6179],\n",
              "           ...,\n",
              "           [-1.6179, -1.9294, -2.1074,  ..., -3.0196, -2.9306, -2.7081],\n",
              "           [-1.5734, -1.8849, -2.1741,  ..., -2.9973, -2.8861, -2.7971],\n",
              "           [-1.5289, -1.9071, -2.3299,  ..., -3.0418, -2.9528, -2.8193]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.3634,  1.3412,  1.4079,  ..., -1.5734, -2.2854, -2.2631],\n",
              "           [ 1.3412,  1.4079,  1.4969,  ..., -1.6179, -2.2631, -2.2409],\n",
              "           [ 1.3412,  1.4079,  1.3634,  ..., -2.2854, -2.7971, -2.8193],\n",
              "           ...,\n",
              "           [-1.8626, -2.2854, -2.2631,  ..., -2.7081, -2.5301, -2.3076],\n",
              "           [-1.8849, -2.2186, -2.3299,  ..., -2.8193, -2.5746, -2.2854],\n",
              "           [-1.9961, -2.2631, -2.3744,  ..., -2.8861, -2.6858, -2.3521]],\n",
              "\n",
              "          [[ 1.3189,  1.4302,  1.4524,  ..., -1.5512, -2.3966, -2.3744],\n",
              "           [ 1.2744,  1.4302,  1.4079,  ..., -1.6179, -2.3744, -2.3744],\n",
              "           [ 1.2967,  1.4302,  1.3857,  ..., -2.1519, -2.7748, -2.7971],\n",
              "           ...,\n",
              "           [-1.9071, -2.2854, -2.2186,  ..., -2.7081, -2.5078, -2.2409],\n",
              "           [-1.8626, -2.2186, -2.2409,  ..., -2.7526, -2.5078, -2.2186],\n",
              "           [-1.9294, -2.1964, -2.3299,  ..., -2.7748, -2.6191, -2.3299]],\n",
              "\n",
              "          [[ 1.3189,  1.4302,  1.3634,  ..., -1.3509, -2.3299, -2.2631],\n",
              "           [ 1.2299,  1.3412,  1.3857,  ..., -1.4622, -2.2409, -2.2409],\n",
              "           [ 1.2522,  1.3634,  1.4079,  ..., -1.8626, -2.6858, -2.6858],\n",
              "           ...,\n",
              "           [-1.9516, -2.3299, -2.2409,  ..., -2.7748, -2.5078, -2.2409],\n",
              "           [-1.8849, -2.2409, -2.2409,  ..., -2.7748, -2.5523, -2.2409],\n",
              "           [-1.9516, -2.2186, -2.3076,  ..., -2.8416, -2.7303, -2.3076]]],\n",
              "\n",
              "\n",
              "         [[[ 1.2827,  1.7246,  1.6614,  ...,  0.9671,  0.9987,  0.4937],\n",
              "           [ 1.2196,  1.7246,  1.7561,  ...,  0.9671,  0.9987,  0.4306],\n",
              "           [ 0.8093,  1.6930,  1.7561,  ...,  0.8409,  0.6515,  0.2728],\n",
              "           ...,\n",
              "           [-0.4216, -0.9266, -1.7156,  ..., -2.9149, -2.7255, -2.3468],\n",
              "           [-0.3900, -0.9266, -1.8418,  ..., -2.9465, -2.7571, -2.5362],\n",
              "           [-0.3900, -1.0212, -1.9050,  ..., -2.9465, -2.7571, -2.6624]],\n",
              "\n",
              "          [[ 1.3458,  1.6614,  1.5668,  ...,  0.9355,  1.0618,  0.3990],\n",
              "           [ 1.2196,  1.6614,  1.5983,  ...,  0.9040,  0.9987,  0.2412],\n",
              "           [ 0.6515,  1.8193,  1.6930,  ...,  0.9040,  0.9671,  0.2728],\n",
              "           ...,\n",
              "           [-0.5478, -0.8634, -1.6840,  ..., -2.9149, -2.7887, -2.4731],\n",
              "           [-0.5163, -0.9581, -1.8103,  ..., -2.9465, -2.7255, -2.6624],\n",
              "           [-0.4216, -1.0528, -1.9050,  ..., -3.0411, -2.7887, -2.6940]],\n",
              "\n",
              "          [[ 1.4405,  1.6930,  1.5668,  ...,  0.9671,  1.0933,  0.3674],\n",
              "           [ 1.2196,  1.7561,  1.7246,  ...,  0.9355,  1.0302,  0.2096],\n",
              "           [ 0.8093,  1.8508,  1.6930,  ...,  1.0302,  0.9355,  0.3043],\n",
              "           ...,\n",
              "           [-0.6741, -1.1159, -1.6209,  ..., -2.9149, -2.6940, -2.3784],\n",
              "           [-0.6741, -1.1159, -1.8734,  ..., -2.9465, -2.7887, -2.6624],\n",
              "           [-0.6109, -1.1475, -2.0943,  ..., -3.0096, -2.8833, -2.6940]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.8508,  1.8193,  1.9139,  ...,  0.3674,  0.5252,  0.5568],\n",
              "           [ 1.8193,  1.9139,  2.0402,  ...,  0.3043,  0.5568,  0.5884],\n",
              "           [ 1.7877,  1.8824,  1.8193,  ...,  0.4306,  0.8724,  0.8409],\n",
              "           ...,\n",
              "           [-0.6109, -1.2106, -1.8418,  ..., -2.4731, -1.7471, -1.4315],\n",
              "           [-0.8950, -1.3684, -1.9996,  ..., -2.6940, -1.9681, -1.5578],\n",
              "           [-1.0528, -1.4315, -2.0628,  ..., -2.7887, -2.1259, -1.6525]],\n",
              "\n",
              "          [[ 1.7877,  1.9455,  1.9771,  ...,  0.3674,  0.5252,  0.5568],\n",
              "           [ 1.7246,  1.9455,  1.9139,  ...,  0.2728,  0.5568,  0.5568],\n",
              "           [ 1.7246,  1.9139,  1.9139,  ...,  0.4306,  0.8724,  0.8409],\n",
              "           ...,\n",
              "           [-0.6425, -1.1790, -1.7787,  ..., -2.6309, -1.8734, -1.4947],\n",
              "           [-0.8319, -1.3369, -1.8734,  ..., -2.7571, -2.0312, -1.6209],\n",
              "           [-0.9266, -1.3053, -1.9996,  ..., -2.7887, -2.1890, -1.7787]],\n",
              "\n",
              "          [[ 1.8193,  1.9771,  1.8508,  ...,  0.4621,  0.3990,  0.4937],\n",
              "           [ 1.6930,  1.8508,  1.8824,  ...,  0.3043,  0.5252,  0.5252],\n",
              "           [ 1.6299,  1.7877,  1.8824,  ...,  0.3990,  0.6199,  0.6199],\n",
              "           ...,\n",
              "           [-0.6109, -1.1475, -1.7156,  ..., -2.7255, -1.8734, -1.4947],\n",
              "           [-0.8003, -1.3053, -1.8103,  ..., -2.8518, -2.1574, -1.7156],\n",
              "           [-0.8950, -1.2737, -1.9050,  ..., -2.9465, -2.4099, -1.8103]]],\n",
              "\n",
              "\n",
              "         [[[ 2.0979,  2.5197,  1.6760,  ...,  0.0790,  1.1035,  0.6214],\n",
              "           [ 2.0376,  2.5197,  1.7664,  ...,  0.0790,  1.1035,  0.5611],\n",
              "           [ 2.4595,  3.3032,  2.0376,  ...,  0.4406,  1.3747,  1.0131],\n",
              "           ...,\n",
              "           [ 0.6816,  0.1995, -0.7949,  ..., -2.2112, -2.0002, -1.6386],\n",
              "           [ 0.5611,  0.0488, -0.9154,  ..., -2.2112, -1.9400, -1.7290],\n",
              "           [ 0.5611, -0.0416, -0.9757,  ..., -2.2112, -1.9400, -1.8496]],\n",
              "\n",
              "          [[ 2.1883,  2.4896,  1.5254,  ...,  0.1392,  1.1035,  0.4707],\n",
              "           [ 2.0677,  2.4896,  1.5555,  ...,  0.1091,  1.0432,  0.3200],\n",
              "           [ 2.1883,  3.3032,  1.9773,  ...,  0.5310,  1.6158,  0.9528],\n",
              "           ...,\n",
              "           [ 0.3803,  0.0790, -0.8552,  ..., -2.0906, -1.9098, -1.6085],\n",
              "           [ 0.2899, -0.1320, -1.0360,  ..., -2.0304, -1.8797, -1.8194],\n",
              "           [ 0.3803, -0.2224, -1.1264,  ..., -2.1208, -1.9400, -1.8496]],\n",
              "\n",
              "          [[ 2.2787,  2.5197,  1.5254,  ...,  0.2598,  1.1939,  0.5008],\n",
              "           [ 2.0677,  2.5800,  1.6760,  ...,  0.2296,  1.1336,  0.3502],\n",
              "           [ 2.3389,  3.3333,  1.9773,  ...,  0.6515,  1.5254,  0.9227],\n",
              "           ...,\n",
              "           [ 0.3200, -0.1018, -0.8853,  ..., -2.1810, -2.0002, -1.6989],\n",
              "           [ 0.1091, -0.3128, -1.1264,  ..., -2.1208, -2.0906, -1.9701],\n",
              "           [ 0.1694, -0.3429, -1.3373,  ..., -2.1810, -2.1810, -2.0002]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.6158,  1.5856,  1.4048,  ...,  0.9227,  2.2787,  2.3088],\n",
              "           [ 1.5856,  1.6760,  1.5254,  ...,  0.8624,  2.3088,  2.3389],\n",
              "           [ 1.4952,  1.5856,  1.4651,  ...,  1.4651,  2.6101,  2.5800],\n",
              "           ...,\n",
              "           [ 0.3200, -0.2525, -1.1565,  ..., -1.7592, -1.2168, -0.9154],\n",
              "           [ 0.0488, -0.4032, -1.3373,  ..., -1.9400, -1.3072, -0.9154],\n",
              "           [-0.1018, -0.4634, -1.3976,  ..., -2.0304, -1.4578, -1.0058]],\n",
              "\n",
              "          [[ 1.5555,  1.7062,  1.4048,  ...,  0.7720,  2.1581,  2.1883],\n",
              "           [ 1.4952,  1.7062,  1.3446,  ...,  0.6816,  2.1883,  2.1883],\n",
              "           [ 1.3747,  1.5555,  1.4651,  ...,  1.2542,  2.5197,  2.4896],\n",
              "           ...,\n",
              "           [ 0.1392, -0.3730, -1.0962,  ..., -1.8496, -1.2770, -0.9154],\n",
              "           [-0.0416, -0.5237, -1.1565,  ..., -2.0304, -1.3976, -1.0058],\n",
              "           [-0.1320, -0.4936, -1.2770,  ..., -2.0605, -1.5482, -1.1565]],\n",
              "\n",
              "          [[ 1.4952,  1.6459,  1.3446,  ...,  0.6515,  1.9773,  2.0677],\n",
              "           [ 1.3747,  1.5254,  1.3747,  ...,  0.5008,  2.0979,  2.0979],\n",
              "           [ 1.4952,  1.6459,  1.5856,  ...,  0.9528,  2.2787,  2.2787],\n",
              "           ...,\n",
              "           [ 0.1392, -0.3730, -1.0661,  ..., -1.8797, -1.2770, -0.9154],\n",
              "           [-0.0416, -0.5237, -1.1264,  ..., -1.9701, -1.4277, -1.0058],\n",
              "           [-0.1320, -0.4936, -1.2168,  ..., -2.0605, -1.6688, -1.0962]]]],\n",
              "\n",
              "\n",
              "\n",
              "        [[[[-1.8021, -1.8021, -1.8021,  ...,  1.0205,  1.0378,  1.0722],\n",
              "           [-1.8021, -1.8021, -1.8021,  ...,  1.0205,  1.0378,  1.0722],\n",
              "           [-1.8537, -1.8537, -1.8193,  ...,  0.9001,  0.9001,  0.9001],\n",
              "           ...,\n",
              "           [-1.9054, -1.9054, -1.9054,  ...,  0.5042,  0.5558,  0.6075],\n",
              "           [-1.9226, -1.9226, -1.9226,  ...,  0.5214,  0.6247,  0.6419],\n",
              "           [-1.9226, -1.9226, -1.9226,  ...,  0.5214,  0.6247,  0.6591]],\n",
              "\n",
              "          [[-1.9226, -1.9226, -1.9226,  ...,  1.0033,  1.0033,  1.0550],\n",
              "           [-1.9226, -1.9226, -1.9226,  ...,  1.0205,  1.0033,  1.0378],\n",
              "           [-1.8881, -1.8881, -1.8537,  ...,  0.9517,  0.9517,  0.9517],\n",
              "           ...,\n",
              "           [-1.9226, -1.9226, -1.9226,  ...,  0.5558,  0.5903,  0.6247],\n",
              "           [-1.9398, -1.9398, -1.9398,  ...,  0.5386,  0.6075,  0.6247],\n",
              "           [-1.9398, -1.9398, -1.9398,  ...,  0.5386,  0.6075,  0.6419]],\n",
              "\n",
              "          [[-1.8881, -1.9054, -1.9398,  ...,  1.0033,  1.0033,  1.0550],\n",
              "           [-1.8881, -1.9054, -1.9398,  ...,  1.0205,  1.0033,  1.0378],\n",
              "           [-1.8709, -1.8709, -1.8365,  ...,  0.9345,  0.9517,  0.9861],\n",
              "           ...,\n",
              "           [-1.9226, -1.9226, -1.9226,  ...,  0.5558,  0.5903,  0.6591],\n",
              "           [-1.9398, -1.9398, -1.9398,  ...,  0.5386,  0.6075,  0.6591],\n",
              "           [-1.9398, -1.9398, -1.9398,  ...,  0.5386,  0.6075,  0.6763]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[-1.7849, -1.7849, -1.4579,  ...,  0.9345,  0.9345,  0.9517],\n",
              "           [-1.8365, -1.8021, -1.4751,  ...,  0.9345,  0.9173,  0.9517],\n",
              "           [-1.8709, -1.8709, -1.7505,  ...,  0.9173,  0.9517,  0.9861],\n",
              "           ...,\n",
              "           [-1.9226, -1.9398, -1.9398,  ...,  0.4870,  0.6075,  0.6591],\n",
              "           [-1.9054, -1.9054, -1.9054,  ...,  0.4870,  0.5731,  0.6075],\n",
              "           [-1.9054, -1.9054, -1.9054,  ...,  0.5042,  0.5903,  0.6247]],\n",
              "\n",
              "          [[-1.8021, -1.8021, -1.4923,  ...,  0.9345,  0.9689,  0.9689],\n",
              "           [-1.7849, -1.7849, -1.5267,  ...,  0.9345,  0.9517,  0.9689],\n",
              "           [-1.9226, -1.9226, -1.8193,  ...,  0.9173,  0.9517,  1.0205],\n",
              "           ...,\n",
              "           [-1.9226, -1.9398, -1.9398,  ...,  0.4870,  0.6075,  0.6591],\n",
              "           [-1.9054, -1.9054, -1.9054,  ...,  0.4870,  0.5903,  0.6247],\n",
              "           [-1.9054, -1.9054, -1.9054,  ...,  0.5386,  0.6075,  0.6763]],\n",
              "\n",
              "          [[-1.7332, -1.7332, -1.3890,  ...,  0.9345,  0.9861,  0.9861],\n",
              "           [-1.7160, -1.7160, -1.4234,  ...,  0.9345,  0.9689,  0.9861],\n",
              "           [-1.9226, -1.9226, -1.7849,  ...,  0.9173,  0.9517,  1.0205],\n",
              "           ...,\n",
              "           [-1.9226, -1.9398, -1.9398,  ...,  0.5042,  0.5558,  0.6247],\n",
              "           [-1.8881, -1.9054, -1.9054,  ...,  0.5214,  0.5731,  0.5903],\n",
              "           [-1.9054, -1.9054, -1.9054,  ...,  0.5558,  0.6075,  0.6075]]],\n",
              "\n",
              "\n",
              "         [[[ 1.1780,  1.1780,  1.1780,  ...,  0.8264,  0.9319,  1.0022],\n",
              "           [ 1.1780,  1.1780,  1.1780,  ...,  0.8264,  0.9319,  1.0022],\n",
              "           [ 1.2484,  1.2484,  1.2132,  ...,  0.8968,  1.0022,  1.0022],\n",
              "           ...,\n",
              "           [ 0.7561,  0.7561,  0.7561,  ...,  0.5100,  0.6155,  0.7209],\n",
              "           [ 0.7209,  0.7209,  0.7209,  ...,  0.5803,  0.6858,  0.7209],\n",
              "           [ 0.7209,  0.7209,  0.7209,  ...,  0.5803,  0.6858,  0.7561]],\n",
              "\n",
              "          [[ 1.2835,  1.2835,  1.3187,  ...,  0.8616,  1.0022,  1.1077],\n",
              "           [ 1.2835,  1.2835,  1.3187,  ...,  0.8968,  1.0022,  1.0726],\n",
              "           [ 1.1780,  1.1780,  1.1429,  ...,  0.9671,  1.0374,  1.0374],\n",
              "           ...,\n",
              "           [ 0.7209,  0.7209,  0.7209,  ...,  0.5451,  0.7209,  0.7913],\n",
              "           [ 0.6858,  0.6858,  0.6858,  ...,  0.5803,  0.7561,  0.7913],\n",
              "           [ 0.6858,  0.6858,  0.6858,  ...,  0.5803,  0.7561,  0.8264]],\n",
              "\n",
              "          [[ 1.2484,  1.2132,  1.2835,  ...,  0.8616,  1.0022,  1.1077],\n",
              "           [ 1.2484,  1.2132,  1.2835,  ...,  0.8968,  1.0022,  1.0726],\n",
              "           [ 1.2132,  1.2132,  1.1780,  ...,  0.9319,  1.0374,  1.1077],\n",
              "           ...,\n",
              "           [ 0.7209,  0.7209,  0.7209,  ...,  0.5451,  0.7209,  0.8616],\n",
              "           [ 0.6858,  0.6858,  0.6858,  ...,  0.5803,  0.7561,  0.8616],\n",
              "           [ 0.6858,  0.6858,  0.6858,  ...,  0.5803,  0.7561,  0.8968]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.1780,  1.1780,  0.9319,  ...,  0.7209,  0.8968,  0.9319],\n",
              "           [ 1.0726,  1.1429,  0.8968,  ...,  0.7209,  0.8616,  0.9319],\n",
              "           [ 1.2132,  1.2132,  1.1077,  ...,  0.7913,  0.9319,  1.0022],\n",
              "           ...,\n",
              "           [ 0.7209,  0.6858,  0.6858,  ...,  0.5803,  0.7209,  0.8264],\n",
              "           [ 0.6506,  0.6506,  0.6506,  ...,  0.6506,  0.7561,  0.8264],\n",
              "           [ 0.6506,  0.6506,  0.6506,  ...,  0.6858,  0.7913,  0.8616]],\n",
              "\n",
              "          [[ 1.1780,  1.1780,  1.0022,  ...,  0.7209,  0.9671,  0.9671],\n",
              "           [ 1.2132,  1.2132,  0.9319,  ...,  0.7209,  0.9319,  0.9671],\n",
              "           [ 1.2835,  1.2835,  1.1429,  ...,  0.7913,  0.9319,  1.0726],\n",
              "           ...,\n",
              "           [ 0.7209,  0.6858,  0.6858,  ...,  0.5803,  0.6858,  0.7913],\n",
              "           [ 0.6506,  0.6506,  0.6506,  ...,  0.6506,  0.7561,  0.8264],\n",
              "           [ 0.6506,  0.6506,  0.6506,  ...,  0.7561,  0.7913,  0.9319]],\n",
              "\n",
              "          [[ 1.1077,  1.1077,  0.9671,  ...,  0.7209,  1.0022,  1.0022],\n",
              "           [ 1.1429,  1.1429,  0.8968,  ...,  0.7209,  0.9671,  1.0022],\n",
              "           [ 1.2835,  1.2835,  1.1780,  ...,  0.8264,  0.9671,  1.1077],\n",
              "           ...,\n",
              "           [ 0.7209,  0.6858,  0.6858,  ...,  0.4748,  0.6155,  0.7561],\n",
              "           [ 0.6858,  0.6506,  0.6506,  ...,  0.5100,  0.7561,  0.7913],\n",
              "           [ 0.6506,  0.6506,  0.6506,  ...,  0.5803,  0.8264,  0.8264]]],\n",
              "\n",
              "\n",
              "         [[[ 2.0334,  2.0334,  1.9934,  ..., -0.3018, -0.2619, -0.2220],\n",
              "           [ 2.0334,  2.0334,  1.9934,  ..., -0.3018, -0.2619, -0.2220],\n",
              "           [ 1.9934,  1.9934,  1.9934,  ..., -0.3218, -0.2818, -0.2818],\n",
              "           ...,\n",
              "           [ 1.7340,  1.7340,  1.7340,  ..., -0.6211, -0.5613, -0.5014],\n",
              "           [ 1.7140,  1.7140,  1.7140,  ..., -0.6411, -0.5213, -0.5014],\n",
              "           [ 1.7140,  1.7140,  1.7140,  ..., -0.6411, -0.5213, -0.4814]],\n",
              "\n",
              "          [[ 2.0134,  2.0134,  1.8937,  ..., -0.3018, -0.3018, -0.2419],\n",
              "           [ 2.0134,  2.0134,  1.8937,  ..., -0.2818, -0.3018, -0.2619],\n",
              "           [ 1.9934,  1.9934,  1.9934,  ..., -0.3417, -0.3417, -0.3417],\n",
              "           ...,\n",
              "           [ 1.7140,  1.7140,  1.7140,  ..., -0.5613, -0.5613, -0.5213],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5812, -0.5413, -0.5213],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5812, -0.5413, -0.5014]],\n",
              "\n",
              "          [[ 1.9735,  1.9535,  1.9136,  ..., -0.3018, -0.3018, -0.2419],\n",
              "           [ 1.9735,  1.9535,  1.9136,  ..., -0.2818, -0.3018, -0.2619],\n",
              "           [ 1.9735,  1.9735,  1.9735,  ..., -0.3617, -0.3417, -0.3018],\n",
              "           ...,\n",
              "           [ 1.7140,  1.7140,  1.7140,  ..., -0.5213, -0.5613, -0.4814],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5413, -0.5413, -0.4814],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5413, -0.5413, -0.4615]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.9336,  1.9336,  1.9735,  ..., -0.3816, -0.3218, -0.3018],\n",
              "           [ 1.8737,  1.9136,  1.9535,  ..., -0.3816, -0.3417, -0.3018],\n",
              "           [ 2.0134,  2.0134,  1.9735,  ..., -0.3617, -0.3018, -0.2619],\n",
              "           ...,\n",
              "           [ 1.7140,  1.6941,  1.6941,  ..., -0.5213, -0.4615, -0.4016],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5413, -0.5014, -0.4615],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5213, -0.4814, -0.4415]],\n",
              "\n",
              "          [[ 2.0334,  2.0334,  1.9934,  ..., -0.3417, -0.2419, -0.2419],\n",
              "           [ 2.0533,  2.0533,  1.9535,  ..., -0.3417, -0.2619, -0.2419],\n",
              "           [ 2.0134,  2.0134,  1.9735,  ..., -0.3617, -0.3018, -0.2220],\n",
              "           ...,\n",
              "           [ 1.7140,  1.6941,  1.6941,  ..., -0.5213, -0.3816, -0.3218],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.5014, -0.3218, -0.2818],\n",
              "           [ 1.6941,  1.6941,  1.6941,  ..., -0.4415, -0.3018, -0.2220]],\n",
              "\n",
              "          [[ 2.0733,  2.0733,  1.9735,  ..., -0.3417, -0.2220, -0.2220],\n",
              "           [ 2.0932,  2.0932,  1.9336,  ..., -0.3417, -0.2419, -0.2220],\n",
              "           [ 1.9735,  1.9735,  1.9336,  ..., -0.4016, -0.3417, -0.2619],\n",
              "           ...,\n",
              "           [ 1.6741,  1.6541,  1.6541,  ..., -0.5014, -0.5213, -0.4415],\n",
              "           [ 1.6741,  1.6541,  1.6541,  ..., -0.4814, -0.4615, -0.4415],\n",
              "           [ 1.6541,  1.6541,  1.6541,  ..., -0.4415, -0.4216, -0.4216]]]],\n",
              "\n",
              "\n",
              "\n",
              "        [[[[-0.6831, -0.4937,  0.5481,  ...,  0.8890,  0.8322,  0.8322],\n",
              "           [-0.6263, -0.6452,  0.2450,  ...,  0.8890,  0.8322,  0.8322],\n",
              "           [-1.5923, -1.5923, -0.8915,  ...,  0.8511,  0.7943,  0.7754],\n",
              "           ...,\n",
              "           [-2.1605, -2.1605, -2.1605,  ...,  0.4913,  0.2450, -0.0959],\n",
              "           [-2.1795, -2.1795, -2.1795,  ...,  0.5102,  0.4155,  0.0935],\n",
              "           [-2.1795, -2.1795, -2.1795,  ...,  0.5102,  0.4534,  0.1882]],\n",
              "\n",
              "          [[-0.7210, -0.6642,  0.5670,  ...,  0.8890,  0.7754,  0.7754],\n",
              "           [-0.7020, -0.7399,  0.2261,  ...,  0.8890,  0.7754,  0.7754],\n",
              "           [-1.6302, -1.6302, -0.9104,  ...,  0.7943,  0.7754,  0.7564],\n",
              "           ...,\n",
              "           [-2.1795, -2.1795, -2.2173,  ...,  0.5102,  0.3018, -0.0202],\n",
              "           [-2.1984, -2.1984, -2.2363,  ...,  0.4913,  0.4155,  0.2071],\n",
              "           [-2.1984, -2.1984, -2.2363,  ...,  0.4344,  0.4155,  0.3587]],\n",
              "\n",
              "          [[-0.7020, -0.6831,  0.5481,  ...,  0.8322,  0.7375,  0.7375],\n",
              "           [-0.7020, -0.7020,  0.2640,  ...,  0.8322,  0.7375,  0.7375],\n",
              "           [-1.6302, -1.6302, -0.9672,  ...,  0.8133,  0.8322,  0.8133],\n",
              "           ...,\n",
              "           [-2.1226, -2.1226, -2.1795,  ...,  0.5291,  0.3587,  0.1124],\n",
              "           [-2.1226, -2.1226, -2.1795,  ...,  0.4534,  0.3776,  0.2829],\n",
              "           [-2.1416, -2.1416, -2.1984,  ...,  0.4155,  0.3208,  0.3966]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[-0.4369, -0.2474,  0.9269,  ...,  0.9458,  0.8511,  0.8322],\n",
              "           [-0.4558, -0.4369,  0.5860,  ...,  0.9458,  0.8511,  0.8322],\n",
              "           [-1.4786, -1.4786, -0.7210,  ...,  0.7754,  0.7186,  0.6996],\n",
              "           ...,\n",
              "           [-2.1795, -2.1795, -2.1795,  ...,  0.3966,  0.1882, -0.7967],\n",
              "           [-2.1605, -2.1605, -2.1605,  ...,  0.4534,  0.3397, -0.5126],\n",
              "           [-2.1795, -2.1795, -2.1795,  ...,  0.4155,  0.3397, -0.4179]],\n",
              "\n",
              "          [[-0.4937, -0.3611,  0.9269,  ...,  0.9080,  0.8511,  0.8322],\n",
              "           [-0.5316, -0.5316,  0.5291,  ...,  0.8890,  0.8322,  0.8133],\n",
              "           [-1.4407, -1.4218, -0.6642,  ...,  0.7754,  0.7375,  0.7186],\n",
              "           ...,\n",
              "           [-2.1795, -2.1795, -2.1795,  ...,  0.4155,  0.2071, -0.7778],\n",
              "           [-2.1605, -2.1605, -2.1605,  ...,  0.4155,  0.3587, -0.5126],\n",
              "           [-2.1605, -2.1605, -2.1605,  ...,  0.4155,  0.3776, -0.3800]],\n",
              "\n",
              "          [[-0.4937, -0.3611,  0.9269,  ...,  0.9080,  0.8511,  0.8322],\n",
              "           [-0.5316, -0.5316,  0.5291,  ...,  0.8890,  0.8322,  0.8133],\n",
              "           [-1.4407, -1.4218, -0.6452,  ...,  0.7754,  0.7375,  0.7186],\n",
              "           ...,\n",
              "           [-2.1795, -2.1795, -2.1795,  ...,  0.4155,  0.2450, -0.7967],\n",
              "           [-2.1605, -2.1605, -2.1605,  ...,  0.4155,  0.3776, -0.5316],\n",
              "           [-2.1605, -2.1605, -2.1605,  ...,  0.4534,  0.3776, -0.3990]]],\n",
              "\n",
              "\n",
              "         [[[-0.1934,  0.1628,  0.3052,  ...,  0.9462,  0.9462,  0.9462],\n",
              "           [-0.0865, -0.1221, -0.2646,  ...,  0.9462,  0.9462,  0.9462],\n",
              "           [ 0.6257,  0.6257,  0.1271,  ...,  1.0175,  1.0887,  1.0531],\n",
              "           ...,\n",
              "           [ 0.5901,  0.5901,  0.5901,  ...,  1.0531,  1.0175,  0.3764],\n",
              "           [ 0.5545,  0.5545,  0.5545,  ...,  1.0887,  1.0887,  0.4833],\n",
              "           [ 0.5545,  0.5545,  0.5545,  ...,  1.0887,  1.1599,  0.6613]],\n",
              "\n",
              "          [[-0.0509,  0.0559,  0.1628,  ...,  0.9462,  0.9462,  0.9462],\n",
              "           [-0.0153, -0.0865, -0.4783,  ...,  0.9462,  0.9462,  0.9462],\n",
              "           [ 0.6970,  0.6970,  0.1271,  ...,  0.9819,  0.9462,  0.9106],\n",
              "           ...,\n",
              "           [ 0.5545,  0.5545,  0.5901,  ...,  1.0175,  1.0531,  0.4477],\n",
              "           [ 0.5189,  0.5189,  0.5545,  ...,  1.0887,  1.0175,  0.6257],\n",
              "           [ 0.5189,  0.5189,  0.5545,  ...,  0.9819,  1.0175,  0.9106]],\n",
              "\n",
              "          [[-0.0509, -0.0153,  0.0915,  ...,  0.9106,  0.9462,  0.9462],\n",
              "           [-0.0509, -0.0509, -0.4427,  ...,  0.9106,  0.9462,  0.9462],\n",
              "           [ 0.6970,  0.6970,  0.1984,  ...,  0.9106,  0.8750,  0.8394],\n",
              "           ...,\n",
              "           [ 0.4477,  0.4477,  0.5189,  ...,  0.8750,  1.1599,  0.6970],\n",
              "           [ 0.4477,  0.4477,  0.5189,  ...,  0.9106,  1.1243,  0.9462],\n",
              "           [ 0.4120,  0.4120,  0.4833,  ...,  0.8394,  1.0175,  1.1599]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[-0.2290,  0.1271,  0.1628,  ...,  0.9106,  0.9462,  0.9106],\n",
              "           [-0.2646, -0.2290, -0.4783,  ...,  0.9106,  0.9462,  0.9106],\n",
              "           [ 0.5901,  0.5901, -0.0509,  ...,  0.9462,  0.9106,  0.8750],\n",
              "           ...,\n",
              "           [ 0.5545,  0.5545,  0.5545,  ...,  1.1243,  1.1955, -0.6563],\n",
              "           [ 0.5189,  0.5189,  0.5189,  ...,  1.0887,  1.1243, -0.4783],\n",
              "           [ 0.4833,  0.4833,  0.4833,  ...,  1.0175,  1.1243, -0.3002]],\n",
              "\n",
              "          [[-0.1221,  0.1271,  0.2696,  ...,  0.9462,  0.9106,  0.8750],\n",
              "           [-0.1934, -0.1934, -0.4783,  ...,  0.9106,  0.8750,  0.8394],\n",
              "           [ 0.5189,  0.5545, -0.0153,  ...,  0.9462,  0.8394,  0.8038],\n",
              "           ...,\n",
              "           [ 0.5545,  0.5545,  0.5545,  ...,  1.0175,  1.0887, -0.7632],\n",
              "           [ 0.5189,  0.5189,  0.5189,  ...,  1.0531,  1.0887, -0.5495],\n",
              "           [ 0.5189,  0.5189,  0.5189,  ...,  1.0531,  1.1243, -0.3002]],\n",
              "\n",
              "          [[-0.1221,  0.1271,  0.2696,  ...,  0.9106,  0.8750,  0.8394],\n",
              "           [-0.1934, -0.1934, -0.4783,  ...,  0.8750,  0.8394,  0.8038],\n",
              "           [ 0.5189,  0.5545,  0.0203,  ...,  1.0175,  0.8394,  0.8038],\n",
              "           ...,\n",
              "           [ 0.5545,  0.5545,  0.5545,  ...,  1.0175,  1.1599, -0.7988],\n",
              "           [ 0.5189,  0.5189,  0.5189,  ...,  1.0175,  1.1243, -0.5851],\n",
              "           [ 0.5189,  0.5189,  0.5189,  ...,  1.0887,  1.1243, -0.3358]]],\n",
              "\n",
              "\n",
              "         [[[ 1.4002,  1.6253,  1.2876,  ..., -0.2210, -0.3335, -0.3335],\n",
              "           [ 1.4677,  1.4452,  0.9273,  ..., -0.2210, -0.3335, -0.3335],\n",
              "           [ 1.8955,  1.8955,  1.4902,  ..., -0.4461, -0.4011, -0.4236],\n",
              "           ...,\n",
              "           [ 1.9856,  1.9856,  1.9406,  ..., -0.3335, -0.0859, -0.4911],\n",
              "           [ 1.9631,  1.9631,  1.9180,  ..., -0.3560, -0.0408, -0.4236],\n",
              "           [ 1.9631,  1.9631,  1.9180,  ..., -0.3560,  0.0042, -0.3110]],\n",
              "\n",
              "          [[ 1.6479,  1.7154,  1.3326,  ..., -0.2660, -0.3560, -0.3560],\n",
              "           [ 1.6704,  1.6253,  0.9273,  ..., -0.2660, -0.3560, -0.3560],\n",
              "           [ 2.0982,  2.0982,  1.6028,  ..., -0.3335, -0.4011, -0.4236],\n",
              "           ...,\n",
              "           [ 1.9631,  1.9631,  1.9180,  ..., -0.2885, -0.1984, -0.5812],\n",
              "           [ 1.9406,  1.9406,  1.8955,  ..., -0.4236, -0.1534, -0.4011],\n",
              "           [ 1.9406,  1.9406,  1.8955,  ..., -0.4911, -0.1534, -0.2210]],\n",
              "\n",
              "          [[ 1.7604,  1.7829,  1.4002,  ..., -0.2885, -0.3786, -0.3786],\n",
              "           [ 1.7604,  1.7604,  1.0624,  ..., -0.2885, -0.3786, -0.3786],\n",
              "           [ 2.0531,  2.0531,  1.5578,  ..., -0.3560, -0.4236, -0.4461],\n",
              "           ...,\n",
              "           [ 2.0081,  2.0081,  2.0081,  ..., -0.3786, -0.1309, -0.4236],\n",
              "           [ 2.0081,  2.0081,  2.0081,  ..., -0.4461, -0.0859, -0.1984],\n",
              "           [ 1.9856,  1.9856,  1.9856,  ..., -0.4911, -0.1534, -0.0633]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.5353,  1.7604,  1.3101,  ..., -0.3560, -0.4461, -0.4686],\n",
              "           [ 1.5128,  1.5353,  0.9048,  ..., -0.3560, -0.4461, -0.4686],\n",
              "           [ 2.0081,  2.0081,  1.5578,  ..., -0.4011, -0.4011, -0.4236],\n",
              "           ...,\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.3335,  0.0718, -1.0991],\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.3786, -0.1084, -1.1216],\n",
              "           [ 1.8955,  1.8955,  1.9406,  ..., -0.4236, -0.1084, -1.0090]],\n",
              "\n",
              "          [[ 1.6479,  1.8055,  1.4227,  ..., -0.3110, -0.3560, -0.3786],\n",
              "           [ 1.6028,  1.6028,  0.9499,  ..., -0.3335, -0.3786, -0.4011],\n",
              "           [ 2.0531,  2.0757,  1.6253,  ..., -0.3560, -0.3560, -0.3786],\n",
              "           ...,\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.4236, -0.0183, -1.1891],\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.5137, -0.1084, -1.1441],\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.5137, -0.0859, -0.9865]],\n",
              "\n",
              "          [[ 1.6479,  1.8055,  1.4227,  ..., -0.2660, -0.3110, -0.3335],\n",
              "           [ 1.6028,  1.6028,  0.9499,  ..., -0.2885, -0.3335, -0.3560],\n",
              "           [ 2.0531,  2.0757,  1.6479,  ..., -0.3335, -0.3560, -0.3786],\n",
              "           ...,\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.3786,  0.0267, -1.2116],\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.4236, -0.0408, -1.1216],\n",
              "           [ 1.9180,  1.9180,  1.9631,  ..., -0.3786, -0.0408, -0.9640]]]],\n",
              "\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "\n",
              "        [[[[ 1.1058,  1.2870,  1.3776,  ...,  0.2227,  0.1095,  0.2001],\n",
              "           [ 1.1285,  1.3323,  1.3323,  ...,  0.2454,  0.1095,  0.1774],\n",
              "           [ 1.1058,  1.0832,  1.1964,  ...,  0.3586,  0.2227,  0.1774],\n",
              "           ...,\n",
              "           [-2.2228, -2.2228, -1.8832,  ..., -2.9021, -2.8795, -2.4945],\n",
              "           [-2.0417, -2.1775, -1.9058,  ..., -2.8342, -2.9021, -2.6304],\n",
              "           [-2.1096, -2.3134, -2.0417,  ..., -3.0154, -3.0833, -2.7663]],\n",
              "\n",
              "          [[ 1.1511,  1.3096,  1.3096,  ...,  0.2680,  0.2906,  0.3133],\n",
              "           [ 1.1511,  1.2190,  1.3323,  ...,  0.3586,  0.1321,  0.2906],\n",
              "           [ 1.1285,  1.1511,  1.1964,  ...,  0.3586,  0.2001,  0.1548],\n",
              "           ...,\n",
              "           [-2.2455, -2.0643, -1.7926,  ..., -2.8568, -2.8568, -2.3360],\n",
              "           [-1.9511, -1.9964, -1.7926,  ..., -2.8116, -2.8342, -2.4266],\n",
              "           [-1.9058, -2.2228, -1.8605,  ..., -2.9927, -2.9927, -2.6078]],\n",
              "\n",
              "          [[ 1.1964,  1.2643,  1.3323,  ...,  0.2680,  0.2454,  0.2906],\n",
              "           [ 1.0832,  1.2417,  1.3096,  ...,  0.3359,  0.0869,  0.2454],\n",
              "           [ 1.1058,  1.1964,  1.2417,  ...,  0.3359,  0.1095,  0.1774],\n",
              "           ...,\n",
              "           [-2.2681, -2.0870, -1.8379,  ..., -2.8342, -2.9021, -2.2681],\n",
              "           [-1.9511, -1.9964, -1.8152,  ..., -2.7436, -2.8568, -2.3134],\n",
              "           [-1.8605, -2.2002, -1.8832,  ..., -2.9021, -3.1059, -2.5851]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.0605,  1.0832,  1.2190,  ...,  0.4718,  0.3586,  0.2454],\n",
              "           [ 0.9926,  1.1285,  1.2190,  ...,  0.4492,  0.3586,  0.1774],\n",
              "           [ 1.2190,  1.3323,  1.1964,  ...,  0.2001,  0.2001,  0.1548],\n",
              "           ...,\n",
              "           [-2.4719, -2.4040, -1.7699,  ..., -2.8116, -2.7210, -2.2908],\n",
              "           [-2.2002, -2.2002, -1.8152,  ..., -2.7436, -2.6757, -2.2681],\n",
              "           [-2.1096, -2.2228, -1.9964,  ..., -2.9248, -2.8795, -2.5398]],\n",
              "\n",
              "          [[ 1.0605,  1.1285,  1.1511,  ...,  0.4265,  0.3586,  0.2454],\n",
              "           [ 0.9926,  1.2417,  1.1285,  ...,  0.4039,  0.3586,  0.2227],\n",
              "           [ 1.1964,  1.2643,  1.2417,  ...,  0.2454,  0.2454,  0.1321],\n",
              "           ...,\n",
              "           [-2.5398, -2.3134, -1.7699,  ..., -2.8116, -2.7436, -2.1322],\n",
              "           [-2.2228, -2.0870, -1.8152,  ..., -2.6531, -2.6757, -2.1775],\n",
              "           [-2.0870, -2.2002, -1.9511,  ..., -2.8568, -2.8568, -2.4945]],\n",
              "\n",
              "          [[ 1.0605,  1.1738,  1.2417,  ...,  0.4492,  0.3812,  0.2680],\n",
              "           [ 1.0605,  1.2417,  1.2417,  ...,  0.4265,  0.3812,  0.2680],\n",
              "           [ 1.1738,  1.3549,  1.2190,  ...,  0.2454,  0.2906,  0.1774],\n",
              "           ...,\n",
              "           [-2.5851, -2.3587, -1.7473,  ..., -2.8116, -2.7663, -2.1096],\n",
              "           [-2.2228, -2.0870, -1.7473,  ..., -2.6531, -2.6983, -2.2455],\n",
              "           [-2.0870, -2.2002, -1.8832,  ..., -2.9021, -2.8795, -2.5625]]],\n",
              "\n",
              "\n",
              "         [[[ 1.3781,  1.6353,  1.7960,  ...,  0.5421,  0.2849,  0.4135],\n",
              "           [ 1.4102,  1.6996,  1.7317,  ...,  0.5743,  0.2849,  0.3814],\n",
              "           [ 1.6996,  1.6674,  1.7960,  ...,  0.4457,  0.1563,  0.0920],\n",
              "           ...,\n",
              "           [ 0.7994,  0.7994, -0.1330,  ..., -1.8371, -0.8725, -0.3259],\n",
              "           [ 0.7351,  0.5421, -0.4867,  ..., -2.3515, -1.4512, -1.0654],\n",
              "           [ 0.6386,  0.3492, -0.6796,  ..., -2.6087, -1.7085, -1.2583]],\n",
              "\n",
              "          [[ 1.4424,  1.6674,  1.6996,  ...,  0.5421,  0.3814,  0.4135],\n",
              "           [ 1.4424,  1.5388,  1.7317,  ...,  0.6707,  0.1563,  0.3814],\n",
              "           [ 1.6031,  1.6353,  1.6996,  ...,  0.4135,  0.0277, -0.0366],\n",
              "           ...,\n",
              "           [ 0.6386,  0.8958, -0.2295,  ..., -1.9978, -1.0333, -0.2938],\n",
              "           [ 0.5743,  0.5100, -0.7118,  ..., -2.4479, -1.6763, -1.0976],\n",
              "           [ 0.6386,  0.1885, -0.8082,  ..., -2.7051, -1.9014, -1.3548]],\n",
              "\n",
              "          [[ 1.4424,  1.5388,  1.7317,  ...,  0.5743,  0.3492,  0.4135],\n",
              "           [ 1.2816,  1.5067,  1.6996,  ...,  0.6707,  0.1242,  0.3492],\n",
              "           [ 1.5710,  1.6996,  1.7639,  ...,  0.4778, -0.0366,  0.0599],\n",
              "           ...,\n",
              "           [ 0.5743,  0.8315, -0.2295,  ..., -2.0300, -1.0976, -0.1973],\n",
              "           [ 0.5743,  0.5100, -0.6796,  ..., -2.4801, -1.8692, -1.0976],\n",
              "           [ 0.7029,  0.2206, -0.7761,  ..., -2.7051, -2.2229, -1.4834]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.4102,  1.4424,  1.6353,  ...,  0.7029,  0.3814,  0.2206],\n",
              "           [ 1.3138,  1.5067,  1.6353,  ...,  0.6707,  0.3814,  0.1242],\n",
              "           [ 1.4424,  1.6031,  1.6996,  ...,  0.2849, -0.1009, -0.1652],\n",
              "           ...,\n",
              "           [ 0.6386,  0.7351,  0.2528,  ..., -1.8049, -0.6475, -0.0366],\n",
              "           [ 0.6707,  0.6707, -0.1973,  ..., -2.4801, -1.4834, -0.9047],\n",
              "           [ 0.7994,  0.6386, -0.4546,  ..., -2.7373, -1.7728, -1.2905]],\n",
              "\n",
              "          [[ 1.4102,  1.5067,  1.5388,  ...,  0.6707,  0.3814,  0.2206],\n",
              "           [ 1.3138,  1.6674,  1.5067,  ...,  0.6386,  0.3814,  0.1885],\n",
              "           [ 1.4424,  1.5388,  1.7317,  ...,  0.4135,  0.0920, -0.0687],\n",
              "           ...,\n",
              "           [ 0.5421,  0.8637,  0.2849,  ..., -1.8692, -0.7761,  0.0920],\n",
              "           [ 0.6064,  0.7994, -0.2616,  ..., -2.5122, -1.6442, -0.9368],\n",
              "           [ 0.7994,  0.6386, -0.4546,  ..., -2.8016, -1.9014, -1.3869]],\n",
              "\n",
              "          [[ 1.4102,  1.5710,  1.6674,  ...,  0.6707,  0.3492,  0.1885],\n",
              "           [ 1.4102,  1.6674,  1.6674,  ...,  0.6386,  0.3492,  0.1885],\n",
              "           [ 1.4102,  1.6674,  1.6996,  ...,  0.4457,  0.0599, -0.1009],\n",
              "           ...,\n",
              "           [ 0.5743,  0.8958,  0.3171,  ..., -1.8692, -0.8082,  0.1242],\n",
              "           [ 0.6064,  0.7994, -0.2295,  ..., -2.3515, -1.5798, -0.9368],\n",
              "           [ 0.7994,  0.6386, -0.4224,  ..., -2.7051, -1.8371, -1.3869]]],\n",
              "\n",
              "\n",
              "         [[[ 1.2150,  1.4623,  1.5242,  ..., -0.3000, -0.3618, -0.2382],\n",
              "           [ 1.2459,  1.5242,  1.4623,  ..., -0.2691, -0.3618, -0.2691],\n",
              "           [ 1.1222,  1.0913,  1.3696,  ..., -0.3618, -0.5473, -0.6092],\n",
              "           ...,\n",
              "           [ 2.4827,  2.4827,  0.9986,  ..., -1.2275, -0.2072,  0.3184],\n",
              "           [ 2.2353,  2.0498,  0.4730,  ..., -1.6604, -0.8874, -0.5164],\n",
              "           [ 2.1425,  1.8643,  0.2875,  ..., -1.9077, -1.1348, -0.7019]],\n",
              "\n",
              "          [[ 1.2768,  1.4933,  1.4314,  ..., -0.2691, -0.2072, -0.1763],\n",
              "           [ 1.2768,  1.3696,  1.4623,  ..., -0.1454, -0.4237, -0.2072],\n",
              "           [ 1.2768,  1.3078,  1.3078,  ..., -0.3000, -0.4237, -0.4855],\n",
              "           ...,\n",
              "           [ 2.2971,  2.5445,  0.9677,  ..., -1.4440, -0.4546,  0.2565],\n",
              "           [ 2.1116,  2.0498,  0.3802,  ..., -1.7222, -1.1039, -0.5473],\n",
              "           [ 2.1735,  1.7406,  0.2875,  ..., -1.9696, -1.3203, -0.7947]],\n",
              "\n",
              "          [[ 1.2768,  1.3696,  1.4623,  ..., -0.3309, -0.3928, -0.3309],\n",
              "           [ 1.1222,  1.3387,  1.4314,  ..., -0.2382, -0.6092, -0.3928],\n",
              "           [ 1.2459,  1.3696,  1.3696,  ..., -0.2691, -0.5164, -0.4237],\n",
              "           ...,\n",
              "           [ 2.3281,  2.5754,  1.0295,  ..., -1.4749, -0.5164,  0.3493],\n",
              "           [ 2.1116,  2.0498,  0.3802,  ..., -1.5676, -1.1348, -0.3928],\n",
              "           [ 2.2353,  1.7715,  0.2875,  ..., -1.7841, -1.4749, -0.7638]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.2768,  1.3078,  1.4933,  ..., -0.1454, -0.4237, -0.5783],\n",
              "           [ 1.1841,  1.3696,  1.4933,  ..., -0.1763, -0.4237, -0.6710],\n",
              "           [ 1.2150,  1.3696,  1.3696,  ..., -0.3928, -0.3618, -0.4237],\n",
              "           ...,\n",
              "           [ 2.4827,  2.5754,  1.6479,  ..., -1.1657,  0.0710,  0.6585],\n",
              "           [ 2.4208,  2.4208,  1.0604,  ..., -1.6295, -0.7329, -0.1763],\n",
              "           [ 2.5445,  2.3899,  0.8131,  ..., -1.8768, -1.0111, -0.5473]],\n",
              "\n",
              "          [[ 1.2150,  1.3078,  1.4005,  ..., -0.1145, -0.4855, -0.6401],\n",
              "           [ 1.1222,  1.4623,  1.3696,  ..., -0.1454, -0.4855, -0.6710],\n",
              "           [ 1.2768,  1.3696,  1.4933,  ..., -0.3618, -0.3000, -0.4546],\n",
              "           ...,\n",
              "           [ 2.4517,  2.7609,  1.5860,  ..., -1.1966,  0.0401,  0.8749],\n",
              "           [ 2.4208,  2.6063,  0.9367,  ..., -1.5986, -0.8256, -0.1454],\n",
              "           [ 2.6063,  2.4517,  0.7512,  ..., -1.8768, -1.0730, -0.5783]],\n",
              "\n",
              "          [[ 1.2150,  1.3696,  1.5242,  ..., -0.1763, -0.4855, -0.6401],\n",
              "           [ 1.2150,  1.4623,  1.5242,  ..., -0.2072, -0.4855, -0.6401],\n",
              "           [ 1.2459,  1.4933,  1.4623,  ..., -0.4237, -0.3000, -0.4546],\n",
              "           ...,\n",
              "           [ 2.4517,  2.7609,  1.6169,  ..., -1.1966,  0.0092,  0.9058],\n",
              "           [ 2.3590,  2.5445,  0.9058,  ..., -1.5058, -0.7947, -0.1763],\n",
              "           [ 2.5445,  2.3899,  0.7203,  ..., -1.8459, -1.0420, -0.6092]]]],\n",
              "\n",
              "\n",
              "\n",
              "        [[[[ 1.1276,  1.1679,  1.3088,  ...,  0.8056,  0.7653,  0.7653],\n",
              "           [ 1.2484,  1.2283,  1.2484,  ...,  0.8056,  0.7854,  0.7653],\n",
              "           [ 0.7452,  1.0068,  1.4094,  ...,  0.7854,  0.8458,  0.8458],\n",
              "           ...,\n",
              "           [-2.3145, -2.3145, -2.3145,  ...,  0.2822,  0.3224,  0.4231],\n",
              "           [-2.3145, -2.3145, -2.3145,  ...,  0.2822,  0.3426,  0.4231],\n",
              "           [-2.3145, -2.3145, -2.3145,  ...,  0.3023,  0.3828,  0.4231]],\n",
              "\n",
              "          [[ 1.1478,  1.2484,  1.3893,  ...,  0.7854,  0.7250,  0.7049],\n",
              "           [ 1.2081,  1.3289,  1.3893,  ...,  0.8056,  0.7452,  0.7049],\n",
              "           [ 0.8257,  1.0471,  1.4497,  ...,  0.7452,  0.7452,  0.7452],\n",
              "           ...,\n",
              "           [-2.3548, -2.3548, -2.3548,  ...,  0.3224,  0.2822,  0.3828],\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.3627,  0.3426,  0.3627],\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.4231,  0.3828,  0.3828]],\n",
              "\n",
              "          [[ 1.1880,  1.3289,  1.4296,  ...,  0.7452,  0.6646,  0.6445],\n",
              "           [ 1.2685,  1.3893,  1.4094,  ...,  0.7653,  0.6848,  0.6445],\n",
              "           [ 0.8056,  1.0068,  1.3692,  ...,  0.7250,  0.7250,  0.7250],\n",
              "           ...,\n",
              "           [-2.3548, -2.3548, -2.3548,  ...,  0.3224,  0.3224,  0.4835],\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.3627,  0.2822,  0.3828],\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.3828,  0.3627,  0.3224]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.1880,  1.2283,  1.2685,  ...,  0.8458,  0.8056,  0.8056],\n",
              "           [ 1.1075,  1.2685,  1.2887,  ...,  0.8861,  0.8458,  0.8458],\n",
              "           [ 0.2218,  0.6244,  1.3289,  ...,  0.8659,  0.8257,  0.8257],\n",
              "           ...,\n",
              "           [-2.3749, -2.3749, -2.3749,  ...,  0.2017,  0.2621,  0.3224],\n",
              "           [-2.3749, -2.3749, -2.3749,  ...,  0.1614,  0.3224,  0.4030],\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.2218,  0.4030,  0.4634]],\n",
              "\n",
              "          [[ 1.1075,  1.2081,  1.2887,  ...,  0.8659,  0.8458,  0.8458],\n",
              "           [ 1.0672,  1.2283,  1.2887,  ...,  0.9263,  0.9062,  0.9062],\n",
              "           [ 0.2621,  0.7049,  1.4296,  ...,  0.8257,  0.8056,  0.8056],\n",
              "           ...,\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.1413,  0.3224,  0.3627],\n",
              "           [-2.3749, -2.3749, -2.3749,  ...,  0.1212,  0.4231,  0.4231],\n",
              "           [-2.3950, -2.3950, -2.3950,  ...,  0.2017,  0.4835,  0.5036]],\n",
              "\n",
              "          [[ 1.1478,  1.2283,  1.3289,  ...,  0.8458,  0.8056,  0.8056],\n",
              "           [ 1.0874,  1.2484,  1.3289,  ...,  0.9062,  0.8659,  0.8659],\n",
              "           [ 0.3023,  0.7452,  1.4698,  ...,  0.8861,  0.8458,  0.8257],\n",
              "           ...,\n",
              "           [-2.3950, -2.3950, -2.4152,  ...,  0.2017,  0.3224,  0.3627],\n",
              "           [-2.3749, -2.3749, -2.3950,  ...,  0.1815,  0.4432,  0.4231],\n",
              "           [-2.3950, -2.3950, -2.4152,  ...,  0.2822,  0.5237,  0.5237]]],\n",
              "\n",
              "\n",
              "         [[[ 1.1036,  1.1751,  1.3896,  ...,  0.9248,  0.9248,  0.9248],\n",
              "           [ 1.3181,  1.2823,  1.2823,  ...,  0.9248,  0.9605,  0.9248],\n",
              "           [ 0.7818,  1.2466,  1.2466,  ...,  0.9963,  0.8890,  0.8890],\n",
              "           ...,\n",
              "           [ 0.7460,  0.7460,  0.7460,  ...,  0.8890,  1.1393,  1.3181],\n",
              "           [ 0.7460,  0.7460,  0.7460,  ...,  0.8890,  1.1036,  1.2466],\n",
              "           [ 0.7460,  0.7460,  0.7460,  ...,  0.9248,  1.1751,  1.2466]],\n",
              "\n",
              "          [[ 0.9963,  1.1751,  1.4969,  ...,  0.9605,  0.9248,  0.8890],\n",
              "           [ 1.1036,  1.3181,  1.4969,  ...,  0.9963,  0.9605,  0.8890],\n",
              "           [ 0.7103,  1.1036,  1.0678,  ...,  1.0321,  0.9605,  0.9605],\n",
              "           ...,\n",
              "           [ 0.7460,  0.7460,  0.7460,  ...,  0.8890,  1.1751,  1.3539],\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.8533,  1.1036,  1.1393],\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.9605,  1.1751,  1.1751]],\n",
              "\n",
              "          [[ 0.9963,  1.2466,  1.4969,  ...,  0.9605,  0.9963,  0.9605],\n",
              "           [ 1.1393,  1.3539,  1.4611,  ...,  0.9963,  1.0321,  0.9605],\n",
              "           [ 0.7460,  1.1036,  1.0321,  ...,  0.9963,  0.9248,  0.9248],\n",
              "           ...,\n",
              "           [ 0.7460,  0.7460,  0.7460,  ...,  0.8890,  1.1751,  1.4611],\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.9605,  1.0321,  1.2108],\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.9963,  1.1751,  1.1036]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 0.8890,  0.9605,  1.1751,  ...,  1.0321,  1.0678,  1.0678],\n",
              "           [ 0.7460,  1.0321,  1.2108,  ...,  1.1036,  1.1393,  1.1393],\n",
              "           [ 0.2812,  0.9963,  1.0321,  ...,  1.0321,  1.0321,  1.0321],\n",
              "           ...,\n",
              "           [ 0.6387,  0.6387,  0.6387,  ...,  0.5315,  0.9248,  1.0321],\n",
              "           [ 0.6387,  0.6387,  0.6387,  ...,  0.6030,  0.9605,  1.1036],\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.7103,  1.1036,  1.2108]],\n",
              "\n",
              "          [[ 0.8175,  0.9963,  1.2466,  ...,  0.9963,  1.0678,  1.0678],\n",
              "           [ 0.7460,  1.0321,  1.2466,  ...,  1.1036,  1.1751,  1.1751],\n",
              "           [ 0.2454,  1.0321,  0.9963,  ...,  1.0321,  0.9963,  0.9963],\n",
              "           ...,\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.5315,  0.9605,  1.0321],\n",
              "           [ 0.6387,  0.6387,  0.6387,  ...,  0.6030,  0.9605,  0.9605],\n",
              "           [ 0.6030,  0.6030,  0.6030,  ...,  0.7460,  1.0678,  1.1036]],\n",
              "\n",
              "          [[ 0.8890,  1.0321,  1.3181,  ...,  1.0678,  1.0678,  1.0678],\n",
              "           [ 0.7818,  1.0678,  1.3181,  ...,  1.1751,  1.1751,  1.1751],\n",
              "           [ 0.2812,  1.0678,  0.9963,  ...,  1.1036,  1.0678,  1.0321],\n",
              "           ...,\n",
              "           [ 0.6030,  0.6030,  0.5672,  ...,  0.5315,  0.8533,  0.9248],\n",
              "           [ 0.6387,  0.6387,  0.6030,  ...,  0.6387,  0.9248,  0.8890],\n",
              "           [ 0.6030,  0.6030,  0.5672,  ...,  0.8175,  1.0678,  1.0678]]],\n",
              "\n",
              "\n",
              "         [[[ 0.8991,  0.9454,  0.5746,  ..., -0.3061, -0.3292, -0.3292],\n",
              "           [ 1.0381,  1.0150,  0.5051,  ..., -0.3061, -0.3061, -0.3292],\n",
              "           [ 1.5943,  1.8956,  1.2235,  ..., -0.1670, -0.3524, -0.3524],\n",
              "           ...,\n",
              "           [ 2.1042,  2.1042,  2.1042,  ..., -0.4219, -0.0280,  0.0879],\n",
              "           [ 2.1042,  2.1042,  2.1042,  ..., -0.4219, -0.0280,  0.0647],\n",
              "           [ 2.1042,  2.1042,  2.1042,  ..., -0.3988,  0.0184,  0.0647]],\n",
              "\n",
              "          [[ 0.8064,  0.9223,  0.7600,  ..., -0.3061, -0.3292, -0.3524],\n",
              "           [ 0.8759,  1.0150,  0.7600,  ..., -0.2829, -0.3061, -0.3524],\n",
              "           [ 1.5016,  1.7566,  1.0613,  ..., -0.1670, -0.3061, -0.3061],\n",
              "           ...,\n",
              "           [ 2.0810,  2.0810,  2.0810,  ..., -0.3524, -0.0743,  0.0416],\n",
              "           [ 2.0579,  2.0579,  2.0579,  ..., -0.3524, -0.0743, -0.0511],\n",
              "           [ 2.0579,  2.0579,  2.0579,  ..., -0.2829, -0.0280, -0.0280]],\n",
              "\n",
              "          [[ 0.8064,  0.9686,  0.8064,  ..., -0.3061, -0.3292, -0.3524],\n",
              "           [ 0.8991,  1.0381,  0.7832,  ..., -0.2829, -0.3061, -0.3524],\n",
              "           [ 1.4553,  1.6871,  1.0150,  ..., -0.1902, -0.3756, -0.3756],\n",
              "           ...,\n",
              "           [ 2.1274,  2.1274,  2.1274,  ..., -0.3988, -0.1207,  0.0647],\n",
              "           [ 2.1042,  2.1042,  2.1042,  ..., -0.3524, -0.1902, -0.0743],\n",
              "           [ 2.1042,  2.1042,  2.1042,  ..., -0.3292, -0.0975, -0.1438]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 1.0845,  1.1308,  0.7137,  ..., -0.1902, -0.2365, -0.2365],\n",
              "           [ 0.9918,  1.1772,  0.7368,  ..., -0.1438, -0.1902, -0.1902],\n",
              "           [ 1.5712,  2.0347,  1.6175,  ..., -0.2365, -0.2597, -0.2597],\n",
              "           ...,\n",
              "           [ 2.0347,  2.0347,  2.0347,  ..., -0.4915, -0.3061, -0.2365],\n",
              "           [ 2.0347,  2.0347,  2.0347,  ..., -0.5378, -0.3292, -0.2365],\n",
              "           [ 2.0115,  2.0115,  2.0115,  ..., -0.4683, -0.2365, -0.1670]],\n",
              "\n",
              "          [[ 1.0845,  1.2004,  0.6905,  ..., -0.1902, -0.2365, -0.2365],\n",
              "           [ 1.0381,  1.2235,  0.6905,  ..., -0.1207, -0.1670, -0.1670],\n",
              "           [ 1.6175,  2.1274,  1.5943,  ..., -0.2597, -0.2829, -0.2829],\n",
              "           ...,\n",
              "           [ 2.0115,  2.0115,  2.0115,  ..., -0.5146, -0.3292, -0.2829],\n",
              "           [ 2.0347,  2.0347,  2.0347,  ..., -0.5610, -0.3292, -0.3292],\n",
              "           [ 2.0115,  2.0115,  2.0115,  ..., -0.4683, -0.2597, -0.2365]],\n",
              "\n",
              "          [[ 1.1308,  1.2235,  0.6905,  ..., -0.2365, -0.2829, -0.2829],\n",
              "           [ 1.0613,  1.2467,  0.6905,  ..., -0.1670, -0.2134, -0.2134],\n",
              "           [ 1.5480,  2.0579,  1.4089,  ..., -0.1438, -0.2365, -0.2597],\n",
              "           ...,\n",
              "           [ 2.0115,  2.0115,  1.9883,  ..., -0.4915, -0.3061, -0.2597],\n",
              "           [ 2.0347,  2.0347,  2.0115,  ..., -0.5146, -0.2829, -0.3061],\n",
              "           [ 2.0115,  2.0115,  1.9883,  ..., -0.3988, -0.1902, -0.1902]]]],\n",
              "\n",
              "\n",
              "\n",
              "        [[[[ 1.2278,  1.1667,  1.1463,  ..., -0.5640, -1.2969, -1.3377],\n",
              "           [ 1.1667,  1.1463,  1.1667,  ..., -0.5843, -1.2766, -1.2562],\n",
              "           [ 1.2685,  1.4517,  1.5128,  ..., -1.5005, -2.2335, -2.2946],\n",
              "           ...,\n",
              "           [-2.3557, -2.3557, -2.3557,  ..., -2.5389, -2.6204, -2.5186],\n",
              "           [-2.3760, -2.3760, -2.3760,  ..., -2.4778, -2.5593, -2.5593],\n",
              "           [-2.3760, -2.3760, -2.3760,  ..., -2.5593, -2.6814, -2.7222]],\n",
              "\n",
              "          [[ 1.2685,  1.1870,  1.1056,  ..., -0.5436, -1.3987, -1.3987],\n",
              "           [ 1.2481,  1.1870,  1.1870,  ..., -0.6047, -1.3377, -1.3173],\n",
              "           [ 1.2074,  1.3296,  1.2481,  ..., -1.4191, -2.2742, -2.2335],\n",
              "           ...,\n",
              "           [-2.3760, -2.3760, -2.3353,  ..., -2.5389, -2.5593, -2.3557],\n",
              "           [-2.3557, -2.3557, -2.3557,  ..., -2.5593, -2.4575, -2.3760],\n",
              "           [-2.3557, -2.3557, -2.3557,  ..., -2.6000, -2.5593, -2.5186]],\n",
              "\n",
              "          [[ 1.4110,  1.2685,  1.1056,  ..., -0.5436, -1.4191, -1.4802],\n",
              "           [ 1.3092,  1.2481,  1.1870,  ..., -0.6250, -1.3784, -1.3580],\n",
              "           [ 1.2278,  1.3703,  1.2074,  ..., -1.2766, -2.2132, -2.1724],\n",
              "           ...,\n",
              "           [-2.3760, -2.3760, -2.3557,  ..., -2.4575, -2.5186, -2.3150],\n",
              "           [-2.3760, -2.3760, -2.3760,  ..., -2.5186, -2.4371, -2.3150],\n",
              "           [-2.3760, -2.3557, -2.3557,  ..., -2.6204, -2.5593, -2.4575]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 0.8613,  1.3296,  1.3092,  ..., -0.3807, -1.3987, -1.3987],\n",
              "           [ 0.6780,  1.3296,  1.3703,  ..., -0.4011, -1.4191, -1.3580],\n",
              "           [ 0.3523,  0.9834,  1.3703,  ..., -1.3377, -2.1724, -2.1928],\n",
              "           ...,\n",
              "           [-2.4575, -2.4778, -2.3964,  ..., -2.3150, -2.3964, -2.1114],\n",
              "           [-2.4778, -2.4778, -2.3964,  ..., -2.3557, -2.3760, -2.1928],\n",
              "           [-2.4778, -2.4778, -2.3964,  ..., -2.5593, -2.6000, -2.4575]],\n",
              "\n",
              "          [[ 0.8409,  1.3499,  1.3906,  ..., -0.3604, -1.4598, -1.4802],\n",
              "           [ 0.6169,  1.3092,  1.4110,  ..., -0.3807, -1.4598, -1.4191],\n",
              "           [ 0.3726,  1.0649,  1.2888,  ..., -1.2766, -2.2132, -2.1928],\n",
              "           ...,\n",
              "           [-2.4168, -2.4371, -2.3760,  ..., -2.3557, -2.4168, -2.1114],\n",
              "           [-2.4371, -2.4371, -2.3353,  ..., -2.3150, -2.3353, -2.2132],\n",
              "           [-2.4371, -2.4371, -2.3353,  ..., -2.4778, -2.5389, -2.4778]],\n",
              "\n",
              "          [[ 0.7798,  1.3092,  1.3499,  ..., -0.2993, -1.3987, -1.4395],\n",
              "           [ 0.5762,  1.2888,  1.3906,  ..., -0.3196, -1.3987, -1.3784],\n",
              "           [ 0.2505,  0.9834,  1.3092,  ..., -1.0322, -2.1317, -2.1317],\n",
              "           ...,\n",
              "           [-2.4575, -2.4778, -2.3964,  ..., -2.3557, -2.4575, -2.1317],\n",
              "           [-2.4778, -2.4778, -2.3353,  ..., -2.3557, -2.3760, -2.2132],\n",
              "           [-2.4778, -2.4778, -2.3353,  ..., -2.4778, -2.6000, -2.4982]]],\n",
              "\n",
              "\n",
              "         [[[ 1.6375,  1.5298,  1.4939,  ...,  0.3088, -0.4453, -0.5171],\n",
              "           [ 1.5298,  1.4939,  1.5298,  ...,  0.2729, -0.4094, -0.3735],\n",
              "           [ 1.1707,  1.4939,  1.6375,  ..., -0.0503,  0.3088,  0.2011],\n",
              "           ...,\n",
              "           [ 0.6679,  0.6679,  0.6679,  ..., -2.8872, -2.4563, -2.2767],\n",
              "           [ 0.6320,  0.6320,  0.6320,  ..., -3.2104, -3.0308, -3.0308],\n",
              "           [ 0.6320,  0.6320,  0.6320,  ..., -3.3540, -3.2463, -3.3181]],\n",
              "\n",
              "          [[ 1.6375,  1.4939,  1.4580,  ...,  0.4525, -0.4812, -0.4812],\n",
              "           [ 1.6016,  1.4939,  1.6016,  ...,  0.3447, -0.3735, -0.3375],\n",
              "           [ 1.4939,  1.7093,  1.6016,  ..., -0.1221,  0.1293,  0.2011],\n",
              "           ...,\n",
              "           [ 0.6679,  0.6679,  0.6320,  ..., -3.0667, -2.5640, -2.2049],\n",
              "           [ 0.5961,  0.5961,  0.5961,  ..., -3.4618, -3.0667, -2.9231],\n",
              "           [ 0.5961,  0.5961,  0.5961,  ..., -3.5336, -3.2463, -3.1745]],\n",
              "\n",
              "          [[ 1.8530,  1.6016,  1.3502,  ...,  0.4525, -0.4453, -0.5530],\n",
              "           [ 1.6734,  1.5657,  1.4939,  ...,  0.3088, -0.3735, -0.3375],\n",
              "           [ 1.4580,  1.7093,  1.5298,  ..., -0.0144,  0.0575,  0.1293],\n",
              "           ...,\n",
              "           [ 0.7398,  0.7398,  0.7039,  ..., -2.9949, -2.5999, -2.2408],\n",
              "           [ 0.6679,  0.6679,  0.7039,  ..., -3.4977, -3.1386, -2.9231],\n",
              "           [ 0.6679,  0.7039,  0.7398,  ..., -3.6772, -3.3540, -3.1745]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 0.7398,  1.5657,  1.6375,  ...,  0.4884, -0.3735, -0.3735],\n",
              "           [ 0.4166,  1.5657,  1.7453,  ...,  0.4525, -0.4094, -0.3016],\n",
              "           [-0.1221,  0.9911,  1.8171,  ...,  0.1293,  0.2370,  0.2011],\n",
              "           ...,\n",
              "           [ 0.7039,  0.6679,  0.6679,  ..., -2.3844, -1.7021, -1.1994],\n",
              "           [ 0.6679,  0.6679,  0.7039,  ..., -2.8872, -2.4204, -2.0972],\n",
              "           [ 0.6679,  0.6679,  0.7039,  ..., -3.2463, -2.8154, -2.5640]],\n",
              "\n",
              "          [[ 0.6320,  1.5298,  1.7093,  ...,  0.5602, -0.3016, -0.3375],\n",
              "           [ 0.2370,  1.4580,  1.7453,  ...,  0.5243, -0.3016, -0.2298],\n",
              "           [-0.2298,  0.9911,  1.6016,  ...,  0.2011,  0.1652,  0.2011],\n",
              "           ...,\n",
              "           [ 0.7039,  0.6679,  0.6320,  ..., -2.4563, -1.7381, -1.1994],\n",
              "           [ 0.6679,  0.6679,  0.5961,  ..., -2.9231, -2.4204, -2.2049],\n",
              "           [ 0.6679,  0.6679,  0.5961,  ..., -3.2104, -2.7795, -2.6717]],\n",
              "\n",
              "          [[ 0.5243,  1.4580,  1.6375,  ...,  0.5243, -0.2657, -0.3375],\n",
              "           [ 0.1652,  1.4221,  1.7093,  ...,  0.4884, -0.2657, -0.2298],\n",
              "           [-0.4453,  0.8475,  1.5298,  ...,  0.4884,  0.1293,  0.1293],\n",
              "           ...,\n",
              "           [ 0.7039,  0.6679,  0.6679,  ..., -2.3844, -1.7381, -1.1635],\n",
              "           [ 0.6679,  0.6679,  0.6320,  ..., -2.8872, -2.4204, -2.1331],\n",
              "           [ 0.6679,  0.6679,  0.6320,  ..., -3.1027, -2.8154, -2.6358]]],\n",
              "\n",
              "\n",
              "         [[[ 1.1191,  1.0367,  1.0093,  ...,  0.2952,  0.7895,  0.7346],\n",
              "           [ 1.0367,  1.0093,  1.0367,  ...,  0.2677,  0.8170,  0.8445],\n",
              "           [ 1.0093,  1.2564,  1.1191,  ...,  0.4874,  1.6684,  1.5860],\n",
              "           ...,\n",
              "           [ 2.5473,  2.5473,  2.5473,  ..., -1.6548, -1.2977, -1.1604],\n",
              "           [ 2.5198,  2.5198,  2.4649,  ..., -1.6822, -1.4900, -1.4900],\n",
              "           [ 2.5198,  2.5198,  2.4649,  ..., -1.7921, -1.6548, -1.7097]],\n",
              "\n",
              "          [[ 1.0093,  0.8994,  0.8994,  ...,  0.4325,  0.8445,  0.8445],\n",
              "           [ 0.9818,  0.8994,  1.0093,  ...,  0.3501,  0.9269,  0.9543],\n",
              "           [ 1.1466,  1.3114,  0.9269,  ...,  0.3226,  1.5585,  1.6135],\n",
              "           ...,\n",
              "           [ 2.3550,  2.3550,  2.4099,  ..., -1.6822, -1.3801, -1.1055],\n",
              "           [ 2.3275,  2.3275,  2.3275,  ..., -1.7646, -1.6548, -1.5449],\n",
              "           [ 2.3275,  2.3275,  2.3275,  ..., -1.8196, -1.7921, -1.7372]],\n",
              "\n",
              "          [[ 1.0367,  0.8445,  0.7346,  ...,  0.3226,  0.7895,  0.7071],\n",
              "           [ 0.8994,  0.8170,  0.8445,  ...,  0.2128,  0.8445,  0.8719],\n",
              "           [ 1.1191,  1.3114,  0.8719,  ...,  0.2952,  1.5036,  1.5585],\n",
              "           ...,\n",
              "           [ 2.4374,  2.4374,  2.4374,  ..., -1.6822, -1.4351, -1.1604],\n",
              "           [ 2.4099,  2.4099,  2.3001,  ..., -1.7646, -1.6822, -1.5175],\n",
              "           [ 2.4099,  2.4374,  2.3275,  ..., -1.9020, -1.8470, -1.7097]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[ 0.4874,  1.1191,  1.0642,  ...,  0.2952,  0.6522,  0.6522],\n",
              "           [ 0.2403,  1.1191,  1.1466,  ...,  0.2677,  0.6248,  0.7071],\n",
              "           [ 1.0642,  1.9156,  1.6409,  ...,  0.2952,  1.4761,  1.4487],\n",
              "           ...,\n",
              "           [ 2.6571,  2.6296,  2.4649,  ..., -1.2428, -0.7485, -0.3640],\n",
              "           [ 2.6296,  2.6296,  2.4099,  ..., -1.5724, -1.3527, -1.1055],\n",
              "           [ 2.6296,  2.6296,  2.4099,  ..., -1.8470, -1.6548, -1.4625]],\n",
              "\n",
              "          [[ 0.2952,  0.9818,  1.0916,  ...,  0.2677,  0.6797,  0.6522],\n",
              "           [-0.0069,  0.9269,  1.1191,  ...,  0.2403,  0.6797,  0.7346],\n",
              "           [ 0.8994,  1.8332,  1.3663,  ...,  0.2403,  1.4212,  1.4487],\n",
              "           ...,\n",
              "           [ 2.6571,  2.6296,  2.5198,  ..., -1.2977, -0.6935, -0.2816],\n",
              "           [ 2.6296,  2.6296,  2.4649,  ..., -1.5175, -1.2703, -1.1055],\n",
              "           [ 2.6296,  2.6296,  2.4649,  ..., -1.7372, -1.5449, -1.4625]],\n",
              "\n",
              "          [[ 0.2128,  0.9269,  1.0367,  ...,  0.2677,  0.7621,  0.7071],\n",
              "           [-0.0619,  0.8994,  1.0916,  ...,  0.2403,  0.7621,  0.7895],\n",
              "           [ 0.7895,  1.7783,  1.4487,  ...,  0.3501,  1.3114,  1.3114],\n",
              "           ...,\n",
              "           [ 2.6571,  2.6296,  2.5198,  ..., -1.3252, -0.7210, -0.2816],\n",
              "           [ 2.6296,  2.6296,  2.4099,  ..., -1.5724, -1.2977, -1.0780],\n",
              "           [ 2.6296,  2.6296,  2.4099,  ..., -1.7372, -1.5999, -1.4625]]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "val = next(sample_iterator)\n",
        "\n",
        "val[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MawFRKSxz5bu"
      },
      "outputs": [],
      "source": [
        "video_tensor = val[0][0]   # Took first video frames out from the batch\n",
        "\n",
        "# Permute the tensor from (C, T, H, W) to (T, H, W, C) for imageio\n",
        "frames_to_save = video_tensor.permute(1, 2, 3, 0)\n",
        "\n",
        "frames_for_gif = frames_to_save.to(torch.uint8).numpy()\n",
        "\n",
        "# Now frames_for_gif has the correct shape (75, 50, 100, 3)\n",
        "imageio.mimsave('./animation.gif', frames_for_gif, fps=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "-EbUOeg1z5ZK",
        "outputId": "d0afd1e5-6adc-4b2a-97ad-710c5a712f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-3.2936375..3.4538727].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78ecd59a1a90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "first_video_tensor = val[0][0]\n",
        "\n",
        "frame_tensor = first_video_tensor[:, 36, :, :]   # 36th frame from the first video\n",
        "\n",
        "frame_to_plot = frame_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "plt.imshow(frame_to_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvC6uIdqz5W0",
        "outputId": "700c902a-e231-4830-c570-0080ca72baea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "place red at x zero please\n"
          ]
        }
      ],
      "source": [
        "first_alignment_tensor = val[1][0]\n",
        "text = ''.join([num_to_char[i.item()] for i in first_alignment_tensor])\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wraW92nm10BS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KZ4-TICZ1z-d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWOvmPoo16e_"
      },
      "source": [
        "## 1.3. Neural Network Design\n",
        "\n",
        "We are using Spatial CNN, a.k.a, 3D Convolution layers to pass the video and eventually condense it to classification problem to predict characters from our defind vocabulary.\n",
        "\n",
        "We are using special loss function, CTC, a.k.a, Connectionist Temporal Classification loss. It is used in training neural networks for sequence problems where the timing of the input data is variable. It is particularly useful in applications like speech recognition and handwriting recognition. CTC is specially built for this type of problem and reduces the duplicates using a special token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vpAp30ac1z7k"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Importing required models from PyTorch for the neural network creation.\n",
        "\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import _LRScheduler # Base class for custom schedulers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-qHv1ufx1z5E"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Model is created as a sequential type which contains three 3D convolutional layers, followed by a time distributed\n",
        "  flattening layer, two Bidirectional GRU and finally a dense layer with 28 outputs and softmax activation for classification\n",
        "  problem.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "class LipNet(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(LipNet, self).__init__()\n",
        "\n",
        "        self.conv_block = nn.Sequential(\n",
        "            # Input: (N, 3, 75, 50, 100) -> (N, C, T, H, W)\n",
        "            nn.Conv3d(3, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(32, 64, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(1, 2, 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
        "\n",
        "            nn.Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
        "        )\n",
        "\n",
        "        self.gru1 = nn.GRU(\n",
        "            input_size=1728, # 96 * 3 * 6\n",
        "            hidden_size=256,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.gru2 = nn.GRU(\n",
        "            input_size=512,  # 256 * 2 from bidirectional GRU\n",
        "            hidden_size=256,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc = nn.Linear(512, vocab_size) # 256 * 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is (N, C, T, H, W)\n",
        "        x = self.conv_block(x)\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3, 4)\n",
        "        batch_size, time_steps, _, _, _ = x.size()\n",
        "        x = x.reshape(batch_size, time_steps, -1)\n",
        "\n",
        "        x, _ = self.gru1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x, _ = self.gru2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc(x)\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "        return F.log_softmax(x, dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "AEAdpXUg1zrx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e_oowcz3ofM"
      },
      "source": [
        "## 1.4. Training the Neural Network\n",
        "\n",
        "We need to define our loss function, optimizers, callbacks and learning rate schedular, all of which requires some type of hyperparameter which need to be tuned for a better model.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Weight initialization is one of the important techniques to get better convergence\n",
        "  and save from felling into the trap of local minima\n",
        "\n",
        "'''\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv3d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                nn.init.orthogonal_(param.data)\n",
        "            else:\n",
        "                nn.init.normal_(param.data)"
      ],
      "metadata": {
        "id": "4fFW4Ag6nEtQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DYwiBMqx_Tex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d03944e-270d-423e-f184-7a9d44a9477a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LipNet(\n",
              "  (conv_block): Sequential(\n",
              "    (0): Conv3d(3, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv3d(32, 64, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(1, 2, 2))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (gru1): GRU(1728, 256, batch_first=True, bidirectional=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (gru2): GRU(512, 256, batch_first=True, bidirectional=True)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=512, out_features=28, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# The vocabulary size is 27 characters + 1 blank token for CTC\n",
        "vocab_size = 28\n",
        "\n",
        "model = LipNet(vocab_size=vocab_size).to(device)\n",
        "\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YDzsM2Hm1zpM"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "'''\n",
        "  There is a need to define a learning rate rescheduler so to reduce the chance of overshooting the point of minima.\n",
        "  This function reduces the learning rate as the number of epochs increases and the model getting closer to optimum.\n",
        "\n",
        "'''\n",
        "\n",
        "def lr_lambda_rule(epoch):\n",
        "    if epoch < 30:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return math.exp(-0.1 * (epoch - 29))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "simE7zoQ1zmZ"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "\n",
        "'''\n",
        "  Initiating the Adam optimizer and learning rate scheduler and CTC Loss.\n",
        "\n",
        "'''\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,      # Halve the LR instead of dividing by 5\n",
        "    patience=5,     # Wait 5 epochs instead of 10\n",
        ")\n",
        "criterion = nn.CTCLoss(blank=0, zero_infinity=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "0gZNIXUp1zhE"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  Fetches a single batch, runs inference, decodes the output,\n",
        "  and prints the original vs. predicted text, at the end of each epoch\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def produce_example(model, dataloader, num_to_char, device):\n",
        "    model.eval()\n",
        "\n",
        "    padded_frames, padded_alignments, frame_lengths, alignment_lengths = next(iter(dataloader))\n",
        "    padded_frames = padded_frames.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_probs = model(padded_frames)\n",
        "        predicted_indices = torch.argmax(log_probs, dim=2)\n",
        "\n",
        "\n",
        "    for i in range(padded_frames.size(0)):\n",
        "        original_indices = padded_alignments[i][:alignment_lengths[i]]\n",
        "        original_text = ''.join([num_to_char[idx.item()] for idx in original_indices])\n",
        "\n",
        "        pred_indices_item = predicted_indices[:, i]\n",
        "\n",
        "        uniqued_indices = torch.unique_consecutive(pred_indices_item)\n",
        "        filtered_indices = [i for i in uniqued_indices if i != 0]\n",
        "\n",
        "        predicted_text = ''.join([num_to_char[idx.item()] for idx in filtered_indices])\n",
        "\n",
        "        print(f\"Original:    {original_text}\")\n",
        "        print(f\"Prediction:  {predicted_text}\")\n",
        "        print('~'*100)\n",
        "\n",
        "\n",
        "    model.train()   # Set the model back to training mode for the next epoch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rmk-AI14D3RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6LuhWORD3L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbGmuxdMD3JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvZIBSUq4GJp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "riIRmYHw4GG_",
        "outputId": "8d705666-959b-457c-cabb-c4dc5b1f20e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint...\n",
            "Resuming training from epoch 52\n",
            "\n",
            "--- Epoch 52/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.4842\n",
            "  [Batch 20/113] Training Loss: 0.5791\n",
            "  [Batch 30/113] Training Loss: 0.4378\n",
            "  [Batch 40/113] Training Loss: 0.6213\n",
            "  [Batch 50/113] Training Loss: 0.5397\n",
            "  [Batch 60/113] Training Loss: 0.4783\n",
            "  [Batch 70/113] Training Loss: 0.4425\n",
            "  [Batch 80/113] Training Loss: 0.4272\n",
            "  [Batch 90/113] Training Loss: 0.5693\n",
            "  [Batch 100/113] Training Loss: 0.5362\n",
            "  [Batch 110/113] Training Loss: 0.4186\n",
            "End of Epoch 52 - Average Training Loss: 0.4985\n",
            "End of Epoch 52 - Average Validation Loss: 0.7506\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue wit r e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i i now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with h e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set reen it o ie soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set red it  x now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  binc green wit f fe soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin red wit  e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 53/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.5247\n",
            "  [Batch 20/113] Training Loss: 0.4436\n",
            "  [Batch 30/113] Training Loss: 0.4616\n",
            "  [Batch 40/113] Training Loss: 0.5502\n",
            "  [Batch 50/113] Training Loss: 0.4498\n",
            "  [Batch 60/113] Training Loss: 0.4148\n",
            "  [Batch 70/113] Training Loss: 0.4699\n",
            "  [Batch 80/113] Training Loss: 0.6401\n",
            "  [Batch 90/113] Training Loss: 0.4612\n",
            "  [Batch 100/113] Training Loss: 0.4692\n",
            "  [Batch 110/113] Training Loss: 0.4220\n",
            "End of Epoch 53 - Average Training Loss: 0.4731\n",
            "End of Epoch 53 - Average Validation Loss: 0.6722\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with h e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with j ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place greed with h fe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at a si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green wit h i now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wit x fe soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place rite by l e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green wit t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 54/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.4857\n",
            "  [Batch 20/113] Training Loss: 0.4357\n",
            "  [Batch 30/113] Training Loss: 0.5833\n",
            "  [Batch 40/113] Training Loss: 0.4878\n",
            "  [Batch 50/113] Training Loss: 0.5671\n",
            "  [Batch 60/113] Training Loss: 0.4695\n",
            "  [Batch 70/113] Training Loss: 0.5050\n",
            "  [Batch 80/113] Training Loss: 0.4334\n",
            "  [Batch 90/113] Training Loss: 0.4120\n",
            "  [Batch 100/113] Training Loss: 0.4386\n",
            "  [Batch 110/113] Training Loss: 0.4811\n",
            "End of Epoch 54 - Average Training Loss: 0.4583\n",
            "End of Epoch 54 - Average Validation Loss: 0.6611\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with h oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i i now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with h fe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j i now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in e it now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  binc green with y fe soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by y e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green wit t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 55/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.4788\n",
            "  [Batch 20/113] Training Loss: 0.3908\n",
            "  [Batch 30/113] Training Loss: 0.4372\n",
            "  [Batch 40/113] Training Loss: 0.3969\n",
            "  [Batch 50/113] Training Loss: 0.3804\n",
            "  [Batch 60/113] Training Loss: 0.4710\n",
            "  [Batch 70/113] Training Loss: 0.3641\n",
            "  [Batch 80/113] Training Loss: 0.4501\n",
            "  [Batch 90/113] Training Loss: 0.3672\n",
            "  [Batch 100/113] Training Loss: 0.3655\n",
            "  [Batch 110/113] Training Loss: 0.4062\n",
            "End of Epoch 55 - Average Training Loss: 0.4323\n",
            "End of Epoch 55 - Average Validation Loss: 0.6907\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with h oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with a ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place greed with h fe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sie non\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in e nit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wih x f soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place rted by l e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green it t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 56/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.3712\n",
            "  [Batch 20/113] Training Loss: 0.4078\n",
            "  [Batch 30/113] Training Loss: 0.3684\n",
            "  [Batch 40/113] Training Loss: 0.5136\n",
            "  [Batch 50/113] Training Loss: 0.4732\n",
            "  [Batch 60/113] Training Loss: 0.3762\n",
            "  [Batch 70/113] Training Loss: 0.4118\n",
            "  [Batch 80/113] Training Loss: 0.3986\n",
            "  [Batch 90/113] Training Loss: 0.4834\n",
            "  [Batch 100/113] Training Loss: 0.4477\n",
            "  [Batch 110/113] Training Loss: 0.4297\n",
            "End of Epoch 56 - Average Training Loss: 0.4163\n",
            "End of Epoch 56 - Average Validation Loss: 0.6861\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with h oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s six now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  plac green with h e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at s sie now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in e eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green it f e psoon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green with t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 57/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.4086\n",
            "  [Batch 20/113] Training Loss: 0.4076\n",
            "  [Batch 30/113] Training Loss: 0.3790\n",
            "  [Batch 40/113] Training Loss: 0.4073\n",
            "  [Batch 50/113] Training Loss: 0.4300\n",
            "  [Batch 60/113] Training Loss: 0.2988\n",
            "  [Batch 70/113] Training Loss: 0.3883\n",
            "  [Batch 80/113] Training Loss: 0.4352\n",
            "  [Batch 90/113] Training Loss: 0.3872\n",
            "  [Batch 100/113] Training Loss: 0.3437\n",
            "  [Batch 110/113] Training Loss: 0.4102\n",
            "End of Epoch 57 - Average Training Loss: 0.4039\n",
            "End of Epoch 57 - Average Validation Loss: 0.6559\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue it u one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with j six now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wit v fee again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u fei now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green by y fe soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in o e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 58/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.3682\n",
            "  [Batch 20/113] Training Loss: 0.3376\n",
            "  [Batch 30/113] Training Loss: 0.4413\n",
            "  [Batch 40/113] Training Loss: 0.4271\n",
            "  [Batch 50/113] Training Loss: 0.3164\n",
            "  [Batch 60/113] Training Loss: 0.3521\n",
            "  [Batch 70/113] Training Loss: 0.3253\n",
            "  [Batch 80/113] Training Loss: 0.3445\n",
            "  [Batch 90/113] Training Loss: 0.4934\n",
            "  [Batch 100/113] Training Loss: 0.3318\n",
            "  [Batch 110/113] Training Loss: 0.4751\n",
            "End of Epoch 58 - Average Training Loss: 0.3832\n",
            "End of Epoch 58 - Average Validation Loss: 0.7059\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue wit e one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with d ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wit v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at v si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  let green in e eix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wih x fe soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by r oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green wit t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 59/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2959\n",
            "  [Batch 20/113] Training Loss: 0.3576\n",
            "  [Batch 30/113] Training Loss: 0.3179\n",
            "  [Batch 40/113] Training Loss: 0.2985\n",
            "  [Batch 50/113] Training Loss: 0.4496\n",
            "  [Batch 60/113] Training Loss: 0.4372\n",
            "  [Batch 70/113] Training Loss: 0.5708\n",
            "  [Batch 80/113] Training Loss: 0.3061\n",
            "  [Batch 90/113] Training Loss: 0.3476\n",
            "  [Batch 100/113] Training Loss: 0.2914\n",
            "  [Batch 110/113] Training Loss: 0.3215\n",
            "End of Epoch 59 - Average Training Loss: 0.3649\n",
            "End of Epoch 59 - Average Validation Loss: 0.6514\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue it d oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i six now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with h ee again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in e eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green with y e soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by y oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green it t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 60/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.3890\n",
            "  [Batch 20/113] Training Loss: 0.3752\n",
            "  [Batch 30/113] Training Loss: 0.3431\n",
            "  [Batch 40/113] Training Loss: 0.3209\n",
            "  [Batch 50/113] Training Loss: 0.3857\n",
            "  [Batch 60/113] Training Loss: 0.2932\n",
            "  [Batch 70/113] Training Loss: 0.3163\n",
            "  [Batch 80/113] Training Loss: 0.3600\n",
            "  [Batch 90/113] Training Loss: 0.3259\n",
            "  [Batch 100/113] Training Loss: 0.3663\n",
            "  [Batch 110/113] Training Loss: 0.3706\n",
            "End of Epoch 60 - Average Training Loss: 0.3479\n",
            "End of Epoch 60 - Average Validation Loss: 0.6361\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue in e one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i it now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place green win v se again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sie soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in e it now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wih d e psease\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by r e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 61/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2654\n",
            "  [Batch 20/113] Training Loss: 0.3846\n",
            "  [Batch 30/113] Training Loss: 0.3353\n",
            "  [Batch 40/113] Training Loss: 0.3235\n",
            "  [Batch 50/113] Training Loss: 0.3075\n",
            "  [Batch 60/113] Training Loss: 0.3214\n",
            "  [Batch 70/113] Training Loss: 0.2724\n",
            "  [Batch 80/113] Training Loss: 0.3020\n",
            "  [Batch 90/113] Training Loss: 0.4684\n",
            "  [Batch 100/113] Training Loss: 0.3413\n",
            "  [Batch 110/113] Training Loss: 0.3938\n",
            "End of Epoch 61 - Average Training Loss: 0.3393\n",
            "End of Epoch 61 - Average Validation Loss: 0.6784\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue it u oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i i now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place greed with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sie soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u eni now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in y f soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green with t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 62/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2802\n",
            "  [Batch 20/113] Training Loss: 0.4132\n",
            "  [Batch 30/113] Training Loss: 0.2610\n",
            "  [Batch 40/113] Training Loss: 0.2867\n",
            "  [Batch 50/113] Training Loss: 0.3213\n",
            "  [Batch 60/113] Training Loss: 0.3067\n",
            "  [Batch 70/113] Training Loss: 0.3184\n",
            "  [Batch 80/113] Training Loss: 0.2919\n",
            "  [Batch 90/113] Training Loss: 0.3446\n",
            "  [Batch 100/113] Training Loss: 0.2733\n",
            "  [Batch 110/113] Training Loss: 0.2702\n",
            "End of Epoch 62 - Average Training Loss: 0.3302\n",
            "End of Epoch 62 - Average Validation Loss: 0.7595\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue wit u oe now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i six now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at t s ine now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u nix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green with d f soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green it t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 63/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2686\n",
            "  [Batch 20/113] Training Loss: 0.3109\n",
            "  [Batch 30/113] Training Loss: 0.2917\n",
            "  [Batch 40/113] Training Loss: 0.3080\n",
            "  [Batch 50/113] Training Loss: 0.2832\n",
            "  [Batch 60/113] Training Loss: 0.2625\n",
            "  [Batch 70/113] Training Loss: 0.2904\n",
            "  [Batch 80/113] Training Loss: 0.3023\n",
            "  [Batch 90/113] Training Loss: 0.2680\n",
            "  [Batch 100/113] Training Loss: 0.3734\n",
            "  [Batch 110/113] Training Loss: 0.3468\n",
            "End of Epoch 63 - Average Training Loss: 0.3098\n",
            "End of Epoch 63 - Average Validation Loss: 0.6093\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue at h oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at t s ie soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in i eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in y f seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place rited by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 64/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.3276\n",
            "  [Batch 20/113] Training Loss: 0.2525\n",
            "  [Batch 30/113] Training Loss: 0.3009\n",
            "  [Batch 40/113] Training Loss: 0.2572\n",
            "  [Batch 50/113] Training Loss: 0.2840\n",
            "  [Batch 60/113] Training Loss: 0.2783\n",
            "  [Batch 70/113] Training Loss: 0.3094\n",
            "  [Batch 80/113] Training Loss: 0.4863\n",
            "  [Batch 90/113] Training Loss: 0.2167\n",
            "  [Batch 100/113] Training Loss: 0.2459\n",
            "  [Batch 110/113] Training Loss: 0.2665\n",
            "End of Epoch 64 - Average Training Loss: 0.2918\n",
            "End of Epoch 64 - Average Validation Loss: 0.6180\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue at h one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with d ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wit v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  lea green at j sine soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in p fe soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green it t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 65/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2823\n",
            "  [Batch 20/113] Training Loss: 0.2776\n",
            "  [Batch 30/113] Training Loss: 0.3004\n",
            "  [Batch 40/113] Training Loss: 0.2366\n",
            "  [Batch 50/113] Training Loss: 0.2793\n",
            "  [Batch 60/113] Training Loss: 0.2982\n",
            "  [Batch 70/113] Training Loss: 0.2625\n",
            "  [Batch 80/113] Training Loss: 0.2988\n",
            "  [Batch 90/113] Training Loss: 0.2738\n",
            "  [Batch 100/113] Training Loss: 0.4337\n",
            "  [Batch 110/113] Training Loss: 0.3505\n",
            "End of Epoch 65 - Average Training Loss: 0.2808\n",
            "End of Epoch 65 - Average Validation Loss: 0.6552\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue wit e one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with i ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  la green at v si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wih f e soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green with t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 66/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.3978\n",
            "  [Batch 20/113] Training Loss: 0.2731\n",
            "  [Batch 30/113] Training Loss: 0.2760\n",
            "  [Batch 40/113] Training Loss: 0.1998\n",
            "  [Batch 50/113] Training Loss: 0.2459\n",
            "  [Batch 60/113] Training Loss: 0.2684\n",
            "  [Batch 70/113] Training Loss: 0.2715\n",
            "  [Batch 80/113] Training Loss: 0.2822\n",
            "  [Batch 90/113] Training Loss: 0.2225\n",
            "  [Batch 100/113] Training Loss: 0.2685\n",
            "  [Batch 110/113] Training Loss: 0.2435\n",
            "End of Epoch 66 - Average Training Loss: 0.2643\n",
            "End of Epoch 66 - Average Validation Loss: 0.6289\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue it h one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place greed wit v fee again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  lay green at j sine now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u eigt now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green iy f fee seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place rite by l e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in x nen again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 67/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2476\n",
            "  [Batch 20/113] Training Loss: 0.2244\n",
            "  [Batch 30/113] Training Loss: 0.3005\n",
            "  [Batch 40/113] Training Loss: 0.2374\n",
            "  [Batch 50/113] Training Loss: 0.2534\n",
            "  [Batch 60/113] Training Loss: 0.3046\n",
            "  [Batch 70/113] Training Loss: 0.3053\n",
            "  [Batch 80/113] Training Loss: 0.2379\n",
            "  [Batch 90/113] Training Loss: 0.2087\n",
            "  [Batch 100/113] Training Loss: 0.1988\n",
            "  [Batch 110/113] Training Loss: 0.2631\n",
            "End of Epoch 67 - Average Training Loss: 0.2512\n",
            "End of Epoch 67 - Average Validation Loss: 0.6005\n",
            "-> Checkpoint saved to models/checkpoint.weights.pt\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue in d one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with o ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red win v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set greed at j sine soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  let green in u seit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green win f fere soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green wit t e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 68/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2319\n",
            "  [Batch 20/113] Training Loss: 0.2262\n",
            "  [Batch 30/113] Training Loss: 0.2839\n",
            "  [Batch 40/113] Training Loss: 0.3839\n",
            "  [Batch 50/113] Training Loss: 0.2587\n",
            "  [Batch 60/113] Training Loss: 0.2808\n",
            "  [Batch 70/113] Training Loss: 0.2351\n",
            "  [Batch 80/113] Training Loss: 0.2673\n",
            "  [Batch 90/113] Training Loss: 0.2467\n",
            "  [Batch 100/113] Training Loss: 0.2037\n",
            "  [Batch 110/113] Training Loss: 0.1466\n",
            "End of Epoch 68 - Average Training Loss: 0.2400\n",
            "End of Epoch 68 - Average Validation Loss: 0.6392\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with e one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin rited with o ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wit v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sine soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u enit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in f f soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green it t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 69/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2092\n",
            "  [Batch 20/113] Training Loss: 0.1593\n",
            "  [Batch 30/113] Training Loss: 0.2118\n",
            "  [Batch 40/113] Training Loss: 0.2055\n",
            "  [Batch 50/113] Training Loss: 0.1836\n",
            "  [Batch 60/113] Training Loss: 0.2212\n",
            "  [Batch 70/113] Training Loss: 0.2068\n",
            "  [Batch 80/113] Training Loss: 0.2572\n",
            "  [Batch 90/113] Training Loss: 0.2826\n",
            "  [Batch 100/113] Training Loss: 0.3007\n",
            "  [Batch 110/113] Training Loss: 0.2682\n",
            "End of Epoch 69 - Average Training Loss: 0.2299\n",
            "End of Epoch 69 - Average Validation Loss: 0.6679\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue wit e one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with o ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at t si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in i eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green with z zte soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 70/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1696\n",
            "  [Batch 20/113] Training Loss: 0.2256\n",
            "  [Batch 30/113] Training Loss: 0.2082\n",
            "  [Batch 40/113] Training Loss: 0.2301\n",
            "  [Batch 50/113] Training Loss: 0.1910\n",
            "  [Batch 60/113] Training Loss: 0.1857\n",
            "  [Batch 70/113] Training Loss: 0.2052\n",
            "  [Batch 80/113] Training Loss: 0.1925\n",
            "  [Batch 90/113] Training Loss: 0.1992\n",
            "  [Batch 100/113] Training Loss: 0.2042\n",
            "  [Batch 110/113] Training Loss: 0.1895\n",
            "End of Epoch 70 - Average Training Loss: 0.2192\n",
            "End of Epoch 70 - Average Validation Loss: 0.6501\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with h one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with b ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sie soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u enit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wih f fere seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l oe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in t one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 71/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1975\n",
            "  [Batch 20/113] Training Loss: 0.2085\n",
            "  [Batch 30/113] Training Loss: 0.2181\n",
            "  [Batch 40/113] Training Loss: 0.2086\n",
            "  [Batch 50/113] Training Loss: 0.1539\n",
            "  [Batch 60/113] Training Loss: 0.1952\n",
            "  [Batch 70/113] Training Loss: 0.2007\n",
            "  [Batch 80/113] Training Loss: 0.2126\n",
            "  [Batch 90/113] Training Loss: 0.1577\n",
            "  [Batch 100/113] Training Loss: 0.2013\n",
            "  [Batch 110/113] Training Loss: 0.2379\n",
            "End of Epoch 71 - Average Training Loss: 0.2137\n",
            "End of Epoch 71 - Average Validation Loss: 0.6128\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue wit d one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place greed with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  let green at j sin now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green win z re soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green witn t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 72/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.2036\n",
            "  [Batch 20/113] Training Loss: 0.1848\n",
            "  [Batch 30/113] Training Loss: 0.1619\n",
            "  [Batch 40/113] Training Loss: 0.1438\n",
            "  [Batch 50/113] Training Loss: 0.1916\n",
            "  [Batch 60/113] Training Loss: 0.3318\n",
            "  [Batch 70/113] Training Loss: 0.3157\n",
            "  [Batch 80/113] Training Loss: 0.1845\n",
            "  [Batch 90/113] Training Loss: 0.2115\n",
            "  [Batch 100/113] Training Loss: 0.1683\n",
            "  [Batch 110/113] Training Loss: 0.1632\n",
            "End of Epoch 72 - Average Training Loss: 0.1972\n",
            "End of Epoch 72 - Average Validation Loss: 0.6672\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with i ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s eix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sine now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u enit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green wih z re soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by m e again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green it t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 73/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1643\n",
            "  [Batch 20/113] Training Loss: 0.1557\n",
            "  [Batch 30/113] Training Loss: 0.1437\n",
            "  [Batch 40/113] Training Loss: 0.1674\n",
            "  [Batch 50/113] Training Loss: 0.2294\n",
            "  [Batch 60/113] Training Loss: 0.1874\n",
            "  [Batch 70/113] Training Loss: 0.1480\n",
            "  [Batch 80/113] Training Loss: 0.2632\n",
            "  [Batch 90/113] Training Loss: 0.1488\n",
            "  [Batch 100/113] Training Loss: 0.2171\n",
            "  [Batch 110/113] Training Loss: 0.1446\n",
            "End of Epoch 73 - Average Training Loss: 0.1827\n",
            "End of Epoch 73 - Average Validation Loss: 0.6278\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue it i one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place green wit v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  lay green at j si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u enit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in f re soon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l nhe again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin gren in t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 74/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1542\n",
            "  [Batch 20/113] Training Loss: 0.1487\n",
            "  [Batch 30/113] Training Loss: 0.1695\n",
            "  [Batch 40/113] Training Loss: 0.1376\n",
            "  [Batch 50/113] Training Loss: 0.1509\n",
            "  [Batch 60/113] Training Loss: 0.1888\n",
            "  [Batch 70/113] Training Loss: 0.2161\n",
            "  [Batch 80/113] Training Loss: 0.1394\n",
            "  [Batch 90/113] Training Loss: 0.1561\n",
            "  [Batch 100/113] Training Loss: 0.1533\n",
            "  [Batch 110/113] Training Loss: 0.1645\n",
            "End of Epoch 74 - Average Training Loss: 0.1568\n",
            "End of Epoch 74 - Average Validation Loss: 0.6053\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with u one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wih v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j six now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  lay green in u eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in f fre seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 75/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1981\n",
            "  [Batch 20/113] Training Loss: 0.1541\n",
            "  [Batch 30/113] Training Loss: 0.1419\n",
            "  [Batch 40/113] Training Loss: 0.1116\n",
            "  [Batch 50/113] Training Loss: 0.1274\n",
            "  [Batch 60/113] Training Loss: 0.1412\n",
            "  [Batch 70/113] Training Loss: 0.1093\n",
            "  [Batch 80/113] Training Loss: 0.1441\n",
            "  [Batch 90/113] Training Loss: 0.1508\n",
            "  [Batch 100/113] Training Loss: 0.1228\n",
            "  [Batch 110/113] Training Loss: 0.1276\n",
            "End of Epoch 75 - Average Training Loss: 0.1453\n",
            "End of Epoch 75 - Average Validation Loss: 0.6085\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with i one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place gred with v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j si now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u enit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in z re seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin green in t ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 76/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1573\n",
            "  [Batch 20/113] Training Loss: 0.1474\n",
            "  [Batch 30/113] Training Loss: 0.1701\n",
            "  [Batch 40/113] Training Loss: 0.1164\n",
            "  [Batch 50/113] Training Loss: 0.1754\n",
            "  [Batch 60/113] Training Loss: 0.1066\n",
            "  [Batch 70/113] Training Loss: 0.1167\n",
            "  [Batch 80/113] Training Loss: 0.1289\n",
            "  [Batch 90/113] Training Loss: 0.1512\n",
            "  [Batch 100/113] Training Loss: 0.1231\n",
            "  [Batch 110/113] Training Loss: 0.1854\n",
            "End of Epoch 76 - Average Training Loss: 0.1392\n",
            "End of Epoch 76 - Average Validation Loss: 0.6281\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue ith h one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wih v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  let green at j sie now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  set green in u nit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in z zere seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin gren in x niet naow\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 77/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.1522\n",
            "  [Batch 20/113] Training Loss: 0.1198\n",
            "  [Batch 30/113] Training Loss: 0.1261\n",
            "  [Batch 40/113] Training Loss: 0.1369\n",
            "  [Batch 50/113] Training Loss: 0.1243\n",
            "  [Batch 60/113] Training Loss: 0.1413\n",
            "  [Batch 70/113] Training Loss: 0.0968\n",
            "  [Batch 80/113] Training Loss: 0.1132\n",
            "  [Batch 90/113] Training Loss: 0.1671\n",
            "  [Batch 100/113] Training Loss: 0.1329\n",
            "  [Batch 110/113] Training Loss: 0.1519\n",
            "End of Epoch 77 - Average Training Loss: 0.1324\n",
            "End of Epoch 77 - Average Validation Loss: 0.6300\n",
            "\n",
            "--- Generating example prediction ---\n",
            "Original:    lay blue with l one again\n",
            "Prediction:  lay blue with u one again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin red with g six now\n",
            "Prediction:  bin red with s ix now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place red with d seven again\n",
            "Prediction:  place red wih v see again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    set green in o six now\n",
            "Prediction:  set green at j sie now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place green at q nine again\n",
            "Prediction:  let green in u eit now\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green by b three again\n",
            "Prediction:  bin green in z zre seon\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    place white by y one again\n",
            "Prediction:  place white by l ne again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Original:    bin green at u one again\n",
            "Prediction:  bin gred it x net again\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "--- Epoch 78/100 ---\n",
            "  [Batch 10/113] Training Loss: 0.0748\n",
            "  [Batch 20/113] Training Loss: 0.1186\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-875979354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Print progress every 10 batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  [Batch {batch_idx+1}/{len(train_loader)}] Training Loss: {loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "'''\n",
        "  Complete training pipeline with callbacks, optimizer, learning rate scheduler\n",
        "  and example prediction.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "start_epoch = 0\n",
        "best_loss = float('inf')\n",
        "save_path = os.path.join('models', 'checkpoint.weights.pt')\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Check if a checkpoint file exists to resume from\n",
        "if os.path.exists(save_path):\n",
        "    print(\"Loading checkpoint...\")\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    start_epoch = 51\n",
        "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
        "\n",
        "\n",
        "# Main Training Loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (frames, alignments, frame_lengths, alignment_lengths) in enumerate(train_loader):\n",
        "        frames = frames.to(device)\n",
        "        alignments = alignments.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        log_probs = model(frames)\n",
        "\n",
        "        loss = criterion(log_probs, alignments, frame_lengths, alignment_lengths)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (batch_idx + 1) % 10 == 0: # Print progress every 10 batches\n",
        "            print(f\"  [Batch {batch_idx+1}/{len(train_loader)}] Training Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    print(f\"End of Epoch {epoch+1} - Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for frames, alignments, frame_lengths, alignment_lengths in test_loader:\n",
        "            frames = frames.to(device)\n",
        "            alignments = alignments.to(device)\n",
        "\n",
        "            log_probs = model(frames)\n",
        "            val_loss = criterion(log_probs, alignments, frame_lengths, alignment_lengths)\n",
        "            running_val_loss += val_loss.item()\n",
        "\n",
        "    avg_val_loss = running_val_loss / len(test_loader)\n",
        "    print(f\"End of Epoch {epoch+1} - Average Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Callbacks Logic\n",
        "    if avg_val_loss < best_loss:\n",
        "        best_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"-> Checkpoint saved to {save_path}\")\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    print(\"\\n--- Generating example prediction ---\")\n",
        "    produce_example(model, test_loader, num_to_char, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij9UG66DFA0P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Complete Single-Batch Overfitting Test ---\n",
        "print(\"Fetching a single batch to overfit...\")\n",
        "frames, alignments, frame_lengths, alignment_lengths = next(iter(train_loader))\n",
        "frames, alignments = frames.to(device), alignments.to(device)\n",
        "\n",
        "print(\"Starting single-batch overfitting test...\")\n",
        "model.train()\n",
        "for i in range(400):\n",
        "    optimizer.zero_grad()\n",
        "    log_probs = model(frames)\n",
        "    loss = criterion(log_probs, alignments, frame_lengths, alignment_lengths)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f\"  Iteration {i+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # --- Decode and Print Prediction ---\n",
        "        predicted_indices = torch.argmax(log_probs.detach(), dim=2)\n",
        "\n",
        "        # Get the first item from the batch to display\n",
        "        pred_indices_item = predicted_indices[:, 0]\n",
        "        uniqued_indices = torch.unique_consecutive(pred_indices_item)\n",
        "        filtered_indices = [idx.item() for idx in uniqued_indices if idx.item() != 0]\n",
        "        predicted_text = ''.join([num_to_char[idx] for idx in filtered_indices])\n",
        "\n",
        "        # Get the original text for comparison\n",
        "        original_indices = alignments[0][:alignment_lengths[0]]\n",
        "        original_text = ''.join([num_to_char[idx.item()] for idx in original_indices])\n",
        "\n",
        "        print(f\"    Original:   '{original_text}'\")\n",
        "        print(f\"    Prediction: '{predicted_text}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrH8K82fD3OZ",
        "outputId": "926247ae-f3bd-48ff-a6ed-cde5663cf4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iteration 20, Loss: 2.0607\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la e onw'\n",
            "  Iteration 40, Loss: 1.9584\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lage  onw'\n",
            "  Iteration 60, Loss: 1.8932\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la e onw'\n",
            "  Iteration 80, Loss: 1.8432\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la g en onw'\n",
            "  Iteration 100, Loss: 1.6901\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la ee a now'\n",
            "  Iteration 120, Loss: 1.6390\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lage onw'\n",
            "  Iteration 140, Loss: 1.5642\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la re now'\n",
            "  Iteration 160, Loss: 1.5181\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la ge now'\n",
            "  Iteration 180, Loss: 1.4678\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la gre now'\n",
            "  Iteration 200, Loss: 1.3831\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'ay gren onw'\n",
            "  Iteration 220, Loss: 1.3217\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la re now'\n",
            "  Iteration 240, Loss: 1.2433\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la gree now'\n",
            "  Iteration 260, Loss: 1.2369\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay gren now'\n",
            "  Iteration 280, Loss: 1.1677\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay gren now'\n",
            "  Iteration 300, Loss: 1.1085\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay ren now'\n",
            "  Iteration 320, Loss: 1.0904\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay gre x now'\n",
            "  Iteration 340, Loss: 1.0596\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay gren now'\n",
            "  Iteration 360, Loss: 0.9692\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'la gren i now'\n",
            "  Iteration 380, Loss: 0.9608\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay gren ow'\n",
            "  Iteration 400, Loss: 0.9317\n",
            "    Original:   'lay green at z six now'\n",
            "    Prediction: 'lay gren now'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V-1UqeSr1WkP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eC2_2a5Cynip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdgx525wyndm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Testing the trained Model"
      ],
      "metadata": {
        "id": "SjUBCTG-YSWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join('models', 'checkpoint.weights.pt')\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Check if a checkpoint file exists to resume from\n",
        "if os.path.exists(save_path):\n",
        "    print(\"Loading checkpoint...\")\n",
        "    model.load_state_dict(torch.load(save_path))"
      ],
      "metadata": {
        "id": "oqkQmd1455i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBnp8Eiv55Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ury__lRS55OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6W_BFO9-55LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf1AtUrh4GB_"
      },
      "outputs": [],
      "source": [
        "test_iterator = iter(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmg4yKF04F_W"
      },
      "outputs": [],
      "source": [
        "sample = next(test_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isYWLJpW4F83"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    yhat = model(sample[0].to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRXUO-OT4F6P",
        "outputId": "4fa71730-53dd-4379-e3a1-c9331f7e46e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n",
            "['lay blue with l one again', 'bin red with g six now', 'place red with d seven again', 'set green in o six now', 'place green at q nine again', 'bin green by b three again', 'place white by y one again', 'bin green at u one again']\n"
          ]
        }
      ],
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "\n",
        "alignments_batch = sample[1]\n",
        "\n",
        "real_texts = [''.join([num_to_char[i.item()] for i in sentence]) for sentence in alignments_batch]\n",
        "print(real_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1EQylNm4F3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c53dc6-f52f-4d1f-8e86-d28d8e2a8e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12  1 25 27  2 12 21  5 27  9  8 27  8 27 15  5 27  1  7  1  9 14]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "first_prediction = yhat[:, 0, :]\n",
        "\n",
        "# greedy approach\n",
        "predicted_indices = torch.argmax(first_prediction, dim=1)\n",
        "uniqued_indices = torch.unique_consecutive(predicted_indices)\n",
        "decoded = torch.tensor([i for i in uniqued_indices if i != 0]).numpy()\n",
        "\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uS4rw7U4F1D",
        "outputId": "af545f82-c0ae-494c-fafe-cc27ab62c233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n",
            "['lay blue ih h oe again', 'bin red with i i now', 'plac green with h e again', 'set green at a sie non', 'set green it h i now', 'bin green wih x fe soon', 'place rited by r e again', 'bin green wit t e again']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  Perform Greedy CTC Decode for the whole batch\n",
        "\n",
        "'''\n",
        "\n",
        "predicted_indices = torch.argmax(yhat, dim=2)\n",
        "\n",
        "decoded_sequences = []\n",
        "\n",
        "for i in range(predicted_indices.size(1)):\n",
        "    item_indices = predicted_indices[:, i]\n",
        "    uniqued_indices = torch.unique_consecutive(item_indices)\n",
        "    filtered_indices = [idx.item() for idx in uniqued_indices if idx.item() != 0]\n",
        "    decoded_sequences.append(filtered_indices)\n",
        "\n",
        "print('~'*100, 'PREDICTIONS')\n",
        "\n",
        "predicted_texts = [''.join([num_to_char[idx] for idx in sentence]) for sentence in decoded_sequences]\n",
        "print(predicted_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chy5hR8c4Fye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvkMpScg4Fv2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVgesore4FtR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Loads a trained model, runs inference on a single video,\n",
        "  and returns both the real (ground truth) and predicted text.\n",
        "\n",
        "'''\n",
        "\n",
        "def predict_video(model_path, video_path, device, num_to_char):\n",
        "\n",
        "    print(\"Loading model from checkpoint...\")\n",
        "    model = LipNet(vocab_size=len(num_to_char))\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # print(f\"Loading video: {video_path}\")\n",
        "    video_tensor = load_video(video_path)\n",
        "    input_tensor = video_tensor.permute(3, 0, 1, 2).unsqueeze(0).to(device)\n",
        "\n",
        "    frames_for_gif = video_tensor.to(torch.uint8).numpy()\n",
        "    imageio.mimsave('./animation.gif', frames_for_gif, fps=10)\n",
        "\n",
        "    # 3. Perform Inference\n",
        "    print(\"Making prediction...\")\n",
        "    with torch.no_grad():\n",
        "        log_probs = model(input_tensor)\n",
        "\n",
        "    # 4. Decode the Predicted Output\n",
        "    predicted_indices = torch.argmax(log_probs.detach(), dim=2)\n",
        "    pred_indices_item = predicted_indices.squeeze(1)\n",
        "    uniqued_indices = torch.unique_consecutive(pred_indices_item)\n",
        "    filtered_indices = [idx.item() for idx in uniqued_indices if idx.item() != 0]\n",
        "    predicted_text = ''.join([num_to_char.get(idx, '') for idx in filtered_indices])\n",
        "\n",
        "    # 5. Load and Decode the Real (Ground Truth) Text\n",
        "    print(\"Loading ground truth text...\")\n",
        "    base_name = os.path.basename(video_path)\n",
        "    file_name, _ = os.path.splitext(base_name)\n",
        "    alignment_path = os.path.join('data', 'alignments', 's1', f'{file_name}.align')\n",
        "\n",
        "    alignments = load_alignments(alignment_path)\n",
        "    real_text = ''.join([num_to_char.get(idx.item(), '') for idx in alignments])\n",
        "\n",
        "    return real_text, predicted_text"
      ],
      "metadata": {
        "id": "dDyGU5TR6dkb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your best saved checkpoint\n",
        "model_checkpoint_path = 'models/checkpoint.weights_75.pt'\n",
        "# Define the path to a video you want to test\n",
        "video_to_test = './data/s1/bbaf2n.mpg'\n",
        "\n",
        "# Run the prediction and get both strings back\n",
        "real_text, predicted_text = predict_video(model_checkpoint_path, video_to_test, device, num_to_char)\n",
        "\n",
        "# Print the final comparison\n",
        "print(f\"Video File:     {video_to_test}\")\n",
        "print()\n",
        "print('~'*50, 'REAL TEXT')\n",
        "print(f\"      {real_text}\")\n",
        "print('~'*50, 'Predicted TEXT')\n",
        "print(f\"      {predicted_text}\")\n"
      ],
      "metadata": {
        "id": "YoZqnvBp6dhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1a37b5-1318-4fee-9d69-b8aa18c3eb59"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from checkpoint...\n",
            "Loading video: ./data/s1/bbaf2n.mpg\n",
            "Making prediction...\n",
            "Loading ground truth text...\n",
            "Video File:     ./data/s1/bbaf2n.mpg\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n",
            "      bin blue at f two now\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Predicted TEXT\n",
            "      bin blue by f fouro now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1a66to19vWUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}